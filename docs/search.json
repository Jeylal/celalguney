[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Celâl and I am a master student in the Political Economy of Capitalism at the University of Geneva. You can have a look to my CV or to my blog posts where I publish stuff related to my studies, readings and research interests.\nMy current project at the moment is my master thesis, which will be about the political economy of political cleavages in Switzerland. You can have a look to the first draft of my master thesis proposal here, which will be subject to frequent improvements.\n\n\n Bachelor in History-Economics-Society (now BA in Political Economy and Economic History) | University of Geneva | 2017-2020\n Complementary Certificate in Applied Statistics | University of Geneva (GSEM) | 2021-2022\n Master in The Political Economy of Capitalism | University of Geneva | 2022 -\n\n\n\nInequality and political cleavages\nInstitutional economics | Evolutionary economics\nPolitical economy and comparative capitalism\nEconomic history | history of economic thought\nData science | statistics & econometrics | history of economic methods and measures\n\n\n\n\n\nFrench - Native\nEnglish - Very proficient\nSpanish - Very proficient\nGerman - Good knowledge"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Crises & cycles\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nInikori about Slavery and the Industrial Revolution\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nHow to do maps with R studio\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSugar, Cochineal and power\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nFrom income brackets to income decile\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nHow did the trust in institutions evolve in Switzerland in the last decades? An analysis of political stability and trust\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nThe vote for the left in the 2015 Swiss National Council Election: a short analysis\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Inikori about Slavery and the Industrial Revolution/Inikori.html",
    "href": "posts/Inikori about Slavery and the Industrial Revolution/Inikori.html",
    "title": "Inikori about Slavery and the Industrial Revolution",
    "section": "",
    "text": "Book Review Africans and the Industrial Revolution in England: A Study in International Trade and Economic Development. By JOSEPH E. INIKORI. Cambridge: Cambridge University Press, 2002. 576 p.\nAfricans and the Industrial Revolution in England written and published in 2002 by Joseph Inikori is certainly one of the major contributions on the role of Africans and international trade in England’s industrialization and long run economic development. Joseph Inikori is an Anglo-Nigerian historian currently professor in the university of Rochester and conducting research in Atlantic World Economic History. He has published several articles on Atlantic slave trade and its impact on England economic development, the culmination of his work and research being Africans and the Industrial Revolution in England which received the Association of African Studies Best Book Prize in 2003, one year after publication. This illustrates the importance of Inikori’s book for African scholars and researchers who are eager to demonstrate the historical importance of Africa and slavery of Africans in the rise of Western Europe (but mostly here England) modernity, economic supremacy and development.\nThe present book has hence established itself as a reference and magnus opus on the causal links between African slavery and the Industrial Revolution in England in the 18th century. It is interesting to note that there are only few economic history books which stress with so much focus and insistence on this causal link between African slaves, Atlantic trade and Industrial Revolution. As Inikori argues in his book, the only major contribution on that matter before him was Eric Williams’ Capitalism and Slavery (1944) which explained that slave trade and production directly contributed to the Industrial Revolution thanks to huge amounts of profits made by British merchants and slavers who then re-invested in the productive sectors which were the basis of the Industrial Revolution. In other words, the accumulation of capital made through African slavery allowed for England’s industrial financial investment at the dawn of the Industrial Revolution. However, Williams’ profit-based argument was heavily criticized, the main critics being about the final use of those slavery-based profits (were they really invested in the Industrial Revolution?); the fact that Britain industrialization required no so much profits and that the funds mainly came from England’s own domestic resources. Inikori is aware of those matters and argues that Williams’ thesis is not so well suited anymore to explain England’s industrialization. He also tries to explain Williams’ focus on profits because of the influence of Keynesianism (in which profits play a great role for investments and growth and Williams wrote and published in the Keynesian Era) but adds that Keynesian theory is valid for already well-developed economies and not so much for pre-industrial England (p. 5-6).\nOne could thus consider Inikori’s book as an attempt to go beyond Williams’ argument and “modernize” the explanations of the links between African slavery, Atlantic commerce and England’s development. To reach this goal, Inikori is heavily influenced by development economics’ conceptual framework. He draws inspirations and insights from prominent development economists such as Albert Otto Hirschman (1915-2012) and Hollis Chenery (1918-1994). The main contribution Inikori draws from development economics is the famous industrialization through import substitution model (ISI), for he argues that Industrial Revolution in England was “the first successful case of import substitution industrialization” (p.10). But what are the links between ISI, African slavery, Atlantic international trade and the Industrial Revolution? Inikori has to prove two mechanisms to support his thesis on the causal links between enslavement and exploitation of Africans, the rise of Atlantic commerce and the Industrial Revolution in England. The first mechanism is the causal link between Atlantic commerce and England’s Industrial Revolution (the former causing the latter). The second is the fact that growing Atlantic international trade and commerce were based on African slave labor in the Americas. We will see that the second mechanism is rather obvious and easily proved and that the first one is the main contentious part of the argument.\nInikori argues that during the Middle Ages onwards (roughly 1086-1660 which is the focus of chapter 2) England developed progressively, from 1086 to 1300 and then from 1475 to 1660, an economy specialized in woolen textile industry and that this industry was mostly export led. This specialization in woolen textile manufactures was England’s first successful ISI accomplished in the 16th century and, along with steady improvements in agriculture, made South England relatively rich. Thus, from 1086 to 1660 England moved from agricultural subsistence production to production for market exchange (p.43). However, market demand reached a limit and England could develop its industry further only through new expanding market demand. Inikori makes an important difference between two types of ISIs: both consist in an economy initially producing primary goods for export which then tries to substitute its imports by import-replacing manufactures thanks to state policies (fist for consumer goods, then for intermediate and capital goods). The distinction between the two models is that the first rely exclusively on internal autonomous forces and the second starts to open at some point to international trade and manufactured exports take a central place. All of Inikori’s argument is to show that England’s success corresponds to the second model (p. 150).\nNew markets for British products were thus found thanks to Atlantic trade and commerce (America’s and Africa’s market demand) which were based on Africans slave labor. After constructing an impressive navy and establishing military dominance in Atlantic Sea in the late 16th century (for example after defeating the Invincible Armada in 1588) and therefore acquiring colonies in America, England obtained access to huge market outlets. However, Inikori does not elaborate further on England’s military dominance of Atlantic Sea and this decisive factor lacks an explanation in the author’s work: why was England in the end militarily superior to the Spanish or the Dutch? The book does not provide a precise answer and Inikori only focuses on shipping in chapter 6 to argue that England’s growing shipping industry was stimulated by rising demand for ships due to overseas trade.\nRegardless, it was the access to new markets in Africa and in America’s colonies which enabled England to further its industrialization through import substitution strategies. Imports of cotton textile from India, for instance, gave impetus to local English entrepreneurs to try to venture into cotton textile manufacturing. Protectionist policies, access to outlets in British American colonies and Africa and raw cotton provided by American colonies where production in plantations were based on Africans slaves labor permitted England to successfully achieve import substitution in the cotton industry which is recognized as one of the most crucial sectors of the Industrial Revolution. The reader could be surprised of the relatively few pages focusing on cotton industry in chapter 9 (about 20 pages: pp.427-451) since the Industrial Revolution mostly began with the cotton industry and its technological improvements, but Inikori is right when he argues that this industry developed under the impetus of access to overseas African and American markets and based on raw cotton provided by slave labor in British American colonies. Nonetheless, I think we could also consider the possibility of counterfactual although it may sound speculative: could have England developed its revolutionary cotton industry without African slave labor? This question is a matter of substitutability degree of labor and imports: one could argue that the specialization of Egypt in raw cotton production in the middle of the 19th shows that imports of raw cotton was perhaps more flexible than what Inikori seems to consider.\n\n\n\nRecently bought slaves in Brazil on their way to the farms of the landowners who bought them c. 1830 (credit: wikipedia)\n\n\nRegardless, Inikori’s methodological work is impressive: it offers vast amounts of quantitative data in table form as well as qualitative data through archival researches of a great varieties of historical reports and records. His quantitative and qualitative archival research and evidence allow the author to provide critical reviews of the existing literature on the subject and even to re-evaluate some estimations for example in chapter 5 in which he discusses the measurement of the importance of slave trading between 1600-1850. However, Inikori’s data analysis seems sometimes futile and can blur his main argument as well as confusing and overwhelming the reader. For instance, the author spends pages of digression discussing in vain population and GDP estimates of Domesday England in chapter 2 or Africa and America population estimates before Atlantic trade’s emergence in chapter 4.\nPerhaps the book’s boldest argument and examination to prove the link between Atlantic trade and England’s Industrial Revolution lies in its regional analysis of pre-industrial England. In fact, the regions which started the Industrial Revolution: Lancashire, Yorkshire and the West Midlands (but mostly Lancashire), were the poorest regions of England at the time with relatively low population, low wages and poor overall wealth. As soon as those regions connected to overseas markets, industry, wages and population grew. Inikori carefully shows that population growth was autonomous in those regions (no migration from agriculturally productive and wealthy South regions), that industry growth was not led by internal demand since there was no national market yet until railroads construction in the 19th century and finally that technological innovations took place in those regions and were thus stimulated by high overseas demand. The only reason left to explain North West England industrial growth is thus the access to overseas markets in America and Africa. This is the central argument of the book and I think the most important, since proving that Atlantic trade was based on Africans’ slave labor is rather indisputable, obvious and largely admitted in the literature.\nIn the end, Africans and the Industrial Revolution in England definitely shows that African slave labor significantly contributed to England’s Industrial Revolution. Notwithstanding, its precise form of contribution, whether it was the decisive and unique causal factor or a factor among many remains a contentious matter. Inikori seems to consider that it was the decisive and unique factor, taking thus, in my opinion, an excessive straightforward position. Economic history phenomenon can rarely be explained through unique factors and when one focuses too much on one possible factor, other important causes can easily be overlooked. Other research exploring the role of colonization of America by England in the Industrial Revolution without taking such exaggerated straightforward perspective can be found for example in Pomeranz’ Great Divergence (2000) which combines multiple factors such as access to overseas markets and lands through colonization of North America (joining thus partly Inikori’s argument) and access to coal to explain England’s Industrial Revolution and which is, I think, a good complement to Inikori’s work. I also believe that Inikori attributes excessive importance on Atlantic trade, discounting the important role of trade with India and China which were also crucial (as we saw, cotton textiles imported by the English East India Company which stimulated ISI strategy in this sector came from India and another example is China’s demand for silver which made America’s silver mines profitable for decades)."
  },
  {
    "objectID": "posts/About cycles and crises/cycles_crises.html",
    "href": "posts/About cycles and crises/cycles_crises.html",
    "title": "Crises & cycles",
    "section": "",
    "text": "One of the most striking phenomena in capitalist mode of production is certainly the recurring and systematic outbreak of financial and economic crises. Since the emergence of capitalism as a mode production in England during the 18th century and its progressive spread in Europe in the 19th and then in the world in the 20th and 21th centuries, the economy of capitalist countries must endure what economists call “business cycles”, that is to say, cyclical appearances of economic booms in production, employment and prices and busts (decline in production, employment and prices).\nHowever, the acknowledgement of business cycles as such took a long and tedious path. The first main broad examination of economic crisis can be found at the beginning of the 19th century during the famous “General Glut Controversy” which involved famous economists such as Say, Ricardo and Malthus. Say, for example, argued that long-term deep economic crisis could not occur because of what will be afterwards called “Say’s law”, that is, the fact that there can be no overall overproduction crisis since production creates its own demand. It creates its own demand mainly because it generates products which can be directly exchanged for other ones. For example, If I produce coffee beans and sell it, all the value I got through selling will be in return my demand for other commodities by the same amount of value. Marx, who can be considered as a pioneer in crisis and business cycles theory, made his critic of Say’s law a point of departure of his bold thoughts on crisis.\n\n\nAs Foley’ Understanding Capital (chapter 9) argues, there is no precise, consistent and modelled theory of crisis in Marx’ writings. In fact, he had diverse and dispersed analysis of different types of economic crisis that Marxists reconstructed and developed afterwards. Nonetheless, Marx’ main point on crisis is the following paradox he underlined: the capitalist system is characterized by an abundance of products (use values) due to tremendous developed productive forces and, at the same time, unfulfilled desires on the part of the working class. According to Marx, the main reason lies in the fact that production is carried under capitalism not to fulfill needs (produce use-value to satisfy needs and desires), but to accumulate profits (or, in Marxist terms, surplus value). Marxists reconstructed then three main theories of crisis: disproportionality crisis, underconsumption crisis and crisis due to the falling rate of profit.\nFirstly, in Capital Volume 2, Marx sets up a model of capital circulation through two department: department I (production of means of production) and II (production of means of consumption). For those two sectors to have balanced growth, there should be a balanced investment level between the two, such that there can be no overproduction in one department and/or not a lack of production in the other. The problem is that it is rarely the case, since capitalist allocate their capital not in order to balance the two department, but to accumulate surplus value. This type of crisis is called “disproportionality crisis”.\nSecondly, the underconsumption theory underlines the striking feature of the inability, under capitalism, to sell all the produced commodities. Since workers only receive a part of the value they produce in the form of wages, aggregate demand has a tendency to be always lower than the supply. Hence, their purchasing power will always be lower than the value of the produced commodities which need to be absorbed. This leaves an excess supply in the market and crisis follows. Foley argues that this version of the underconsumption theory is simplistic, because that part of the value that the worker does not get goes as income to the capitalist, who can also support additional demand for output (through consumption, or through investment, a point whom which Marx was aware of). At this precise point, Rosa Luxemburg had an important and rather unorthodox analysis. She argued that capitalist economy is structurally incapable of generating enough aggregate demand. Her argument is that even if capitalists have enough money and the willingness to invest (which would normally support aggregate demand), they cannot invest ad infinitum. In effect, the purpose of investment is in fine also to produce consumption goods (it is also its justification), one cannot invest only to accumulate means of production per se. Foley underlines the fact that this analysis by Luxemburg is strikingly un-Marxist, since Marx himself argued that the ultimate goal of capitalist production is accumulation of surplus value.\nThirdly Foley explains two versions of the falling rate of profit theory, the first being the “profit squeeze” theory and the second the tendency of falling profit rate: 1) The expansion phase of the business cycle leads to higher employment, the workers’ bargaining power rises and thus wages rise. That leads to a fall of the profit rate and this leads to a crisis since capitalists do not invest further until production and employment fall enough to decrease workers’ bargaining power so that wages decrease and profit rate can go up. 2) Pressured by competition and the search for profit to innovate, the capitalists tend to replace more and more labor by capital, that is, mainly machinery and equipment goods. In Marxist terms, there is a rise of the organic composition of capital (c/v with c=constant capital: machinery, equipment; and v the variable capital: wages) which leads to a fall of the profit rate (defined as p=s/(c+v) = (s/v)/(c/v+1) with s the surplus value).\n\n\n\nApart from Marx and Marxists scholars, another trend emerged in the end of the 19th and in the first half the of 20th century: economists who became increasingly interested in the measurement and analysis of business cycles. The biggest impetus in that matter can surely be accredited to Wesley Clair Mitchell (1874-1948) who was the first director of the National Bureau of Economic Research (founded in 1920) and conducted tremendous research on the measurement and analysis of business cycles. Influenced by Thorstein Veblen and his critic of neoclassical economics, Mitchell sought a new way of conducting economic analysis and research, mainly through historical and empirical data analysis. He was convinced that his empirical and inductive approach (constructing new theories from empirical evidence) would make older economic theories obsolete: “quantitative analysis” would produce more robust economic reasonings than “qualitative analysis”, that is, neoclassical deductive approach. Conclusions Mitchell drew from his work are remarkably similar to Marx’: business cycles are chiefly driven by the incessant pursuit for profit. Assuredly, Mitchell’s work paved the way to a golden age of statistical and quantitative analysis of business cycles in the 1920s, so much that even economists hitherto not interested in that domain sought to bring their own contribution to business cycle analysis. A striking example is surely Irving Fisher (1867-1947) and his debt-deflation theory. Fisher, who recognized that he was a newcomer on the subject, made a distinction between “forced cycles”, cycles determined and driven by external factors (Fisher gives the example of the sun spot theory which sought to explain economic cycles through astronomical cycles) and “free cycles”, namely, cycles whose prime movers are not external, but inherent and intrinsic to the cycle. It is to this latter case, the free cycles, that Fisher wants to explain taking what he calls a “economic science” point of departure as opposed to economic history which only describe business cycles. Fisher wants to identify relations and tendencies that drive the cycles. His main idea is that the main two factors are (1) over-indebtedness and (2) deflation, the former being more important than the latter. The state of over-indebtedness leads to worries on the part of either debtors and/or creditors. As debtors try to sell their assets to pay back their debts, the quantity of money in circulation and the velocity of money decline (agents consume less to save). This leads to a fall in price level and a paradoxical situation where the more economic agents try to get rid of their debts, the more its value in real terms rise: “the more the debtors pay, the more they owe” (Fisher 1933: 54). The fall in general price level leads to a fall of profit rate and hence to a decline of production and employment. This leads to general pessimism, loss of confidence and hoarding, the value of money rises even more, prices decline further and the real interest rate rises. Fisher argues it would be insane not to intervene through economic policy and that the economy should not be left to natural market forces: reflation policy becomes necessary. However, it would not be sufficient, since the main problem of the tendency towards over-indebtedness remains. This leads Fisher to explore some of the reasons which drive the economy towards this state of over-borrowing and over-indebtedness. He argues, finally, that the mains factors are the new investments opportunities associated with great profit expectations (because it will encourage agents to borrow to invest). Those new investments opportunities are, in return, created by new inventions and technological breakthrough and progress.\n\n\n\nBabson presenting one of his famous babsoncharts on business cycles\n\n\n\n\n\nTo sum up, analysis of business cycles began first with inquiries and reflections around market gluts and economic crises. As we saw, Marx and Marxists scholars can be considered as pioneers in the analysis of crises and business cycles. Outside Marxism, it was W.C. Mitchell who gave the greater impetus into business cycles analysis. As stated above, Mitchell and Marx analysis of business cycles as profit driven are similar. Nonetheless, I think Marx’ investigation goes one step further, as he also sought to explain the origins of profit through exploitation and the extraction of surplus value. Notwithstanding, Mitchell’s contribution improved greatly the quantitative measurement and analysis of business cycles in such a way that it even drew a mainstream neoclassical economist such as Irving Fisher to elaborate a bold economic theory regarding business cycles. However, if Fisher’s debt-deflation theory provides insights into the economic mechanisms of economic crises and cycles, it is limited by the fact that it neglects the political economy/ political aspects which have an important role in business cycles (one could also argue that Mitchell also omits this fact, as many business cycles economists did). In conclusion, I would like to acknowledge the important works of Kalecki, who, in that matter, successfully incorporated a political economy dimension into business cycle analysis, an analysis I find particularly valuable (this theory is briefly explained in Foley’s book chapter). In his political business cycle theory, Kalecki argues that cycles are characterized by shifting class alliances between the working class, the business class and the rentiers: during a crisis, the business class pressures the state to revive the economy, aligning thus its class interests with those of the working class. As production and employment rise thanks to state intervention, the business side becomes progressively more reluctant to it, because it loses bargaining power (jobs are secured and workers do not fear unemployment and sacks). As employment and inflation rise, the capitalists have incentive to pressure the state to conduct more orthodox economic policy: this puts an end to the expansion phase of the political business cycle until the economy slumbers once again in a crisis in which state intervention is once again required and so on and so forth. Foley argues that Kalecki’s political business cycle model is a recent underconsumptionist theory, because it stresses the incapacity/unwillingness of a capitalist-dominated society to tolerate a high level of aggregate demand for too long."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Welcome !",
    "section": "Education",
    "text": "Education\n\nBachelor in History-Economics-Society (now BA in Political Economy and Economic History) | University of Geneva | 2017-2020\nComplementary Certificate in Applied Statistics | University of Geneva (GSEM) | 2021-2022\nMaster in The Political Economy of Capitalism | University of Geneva | 2022 -"
  },
  {
    "objectID": "posts/Sugar, Cochineal and Power/sugar cochineal power.html",
    "href": "posts/Sugar, Cochineal and Power/sugar cochineal power.html",
    "title": "Sugar, Cochineal and power",
    "section": "",
    "text": "“The wealth of societies in which the capitalist mode of production prevails appears as an ‘immense collection of commodities’ […] Our investigation therefore begins with the analysis of the commodity” (Marx 1990, 124). So is the incipit of one of the most famous and important books in political economy. If Marx saw in the commodity the most crucial and elementary unit of abstraction in the capitalist mode of production, so much that he spent the first and most tedious pages of his magnus opus dedicated to its analysis and decortication, the commodity per se, that is, as a focus of historical and economic analysis, is rather rare in economics and economic history. For instance, mainstream economics reduces commodities to any objects or services bringing utility to consumers, abstracting from its historical and political dimensions.\nNonetheless, the two texts I will review in this critical summary are attempts to fill this gap and put the commodity back into the heart of not only economics, but also of social and historical analysis. These two texts share indeed a common characteristic: they both focus on a single commodity. Mintz’ book chapter Power (from Sweetness and Power, The Place of Sugar in Modern History (1985)) focuses on sugar from an anthropological perspective whereas Marichal’s book chapter Mexican Cochineal and the European Demand for American Dyes, 1550-1850 (2006) concentrates on cochineal from an economic history point of view. Another peculiar common characteristic of the two papers is that sugar and cochineal, a dyestuff product which is used for its crimson color, are both important inputs for a great number of final products: they are both illustrative examples of intermediary goods constituting a great part of global value chains.\nIn this critical summary, I will first summarize those two texts by outlining their main hypotheses and arguments in a comparative approach. I will then make some critical remarks and comments on what I believe are the positive aspects and chief contributions as well as the flaws and weaknesses of those two papers.\n\n\nMarichal’s analysis of the rise and decline of cochineal production and trade rests upon three main hypotheses. The first one is that the prosperity of cochineal production and trade in Oaxaca, the main farming region of cochineal in Mexico, from the 16th century on was demand led. He advances two reasons for this strong demand, mostly driven by the upper classes of Europe, namely the Church, the nobility, and other elites. One reason is cultural and symbolic: cochineals produce a particularly magnificent crimson color that the nobility and the church associated with symbols of prestige and power. The other reason is physical: cochineal has physical properties which make it materially more advantageous compared to its competitors (kermes for example). This strong demand thus made cochineal highly profitable. Trade, production, and prices thus boomed from the 16th until the late 18th century which marked the start of a long run decline. Mintz’ analysis of how sugar became such an essential and highly demanded commodity is more nuanced. In fact, Mintz’s text is an attempt to answer the following question: how and why did sugar become one of the most widespread and consumed commodities in British society? An obvious and straightforward answer would be, as Marichal argues in the cochineal’s case, that humans are naturally inclined to accept sugar in their consumption habits because of its physical properties. As an anthropologist, Mintz knows that there is nothing natural in the growth of sugar demand. More elaborated answers would be for instance that sugar’s consumption habits spread from the upper classes to the lower classes through imitation (what Mintz calls “intensification”), or the constant tendency of sugar prices to fall. None of these answers are convincing enough for Mintz, whose argument is that the structural transformations of the working conditions and schedules of the British workers, during a transition process from an agricultural economy to an industrial one from circa the 16th century to the 19th century, were the real reason behind sugar’s tremendous prosperity as an essential commodity with strong meaning and signification for its consumers. Mintz explores the dual “meaning” of sugar. On the one hand, sugar replaced honey as a signification of sweetness, happiness, endearment, and tenderness (the “inside meaning” of sugar in anthropological terms) for the common British people. On the other hand, sugar became a symbol of power and prosperity for the imperialistic British ruling classes which had an interest in sugar production and trading made possible by the exploitation of African slaves in the Caribbean plantations. This represents the “outside meaning” of sugar.\n\n\n\nColonial sugar cane manufacturing\n\n\n\n\n\nSecondly, Marichal argues that the stability and success of cochineal’s mode of production were the results of the repartimiento system. The latter was the product of active Spanish colonial policy and merchants’ activity: local Oaxaca bureaucrats obtained funds from Mexican merchants and lent those funds to indigenous cochineal farmers. Indigenous farmers had then to produce cochineals and pay back the functionaries in kind. Marichal argues that the end of the repartimiento system was one of the main reasons for the decline of cochineal production after the late 18th century, which as further exacerbated by the invention of synthetic dyes during the second industrial revolution during the 19th century. This is the third and last hypothesis of Marichal. For Mintz, the availability of sugar was also the product of deliberate British imperialistic policy and is linked to the “outside meaning” explained above. However, the anthropologist argues that sugar demand itself was a product of British government policy: demand on the side of the British masses had to be planned, constructed and stimulated as well. The introduction of rum in the British army, of sugar in almshouses and the abolition of tariffs and duties are example of this active policy so that both “outside” and “inside” meanings of sugar could become unified. Critics and comments\nThese two texts are both instructive and captivating. They offer an enlightening history of sugar and cochineal, giving a lot of data and information on the economic history, modes of production and demand formation processes of those two commodities. The heuristic approach of taking a commodity as a unit of analysis is certainly the most interesting aspect of the two papers.\nFor instance, by focusing on cochineal production in Oaxaca, Marichal deconstructs some prevalent commonplaces of Spanish colonial history and mercantilist policy. One learns that Spaniards were not only interested in silver and gold, which is a widespread cliché in economic history , and that they in fact also sought to capture and exploit other profitable businesses as the market for dyes. The description of the repartimiento system and of its functional role in the stability of cochineal production are convincing and show to what extent Spanish colonization, traditionally considered as mercantilist, was capitalist regarding some sectors (here cochineal production and exchange). However, his argument has some blind spots. First, he totally neglects the importance of class struggle within the repartimiento system and seems to consider the Mexican Revolution of 1820 only as an exogenous shock to the system, without considering the possibility that the fall of the repartimiento system could have been the result of its own contradictions and could have been (this is only a hypothetical possibility) somehow linked to internal class struggle, social movements and uprisings or even the Mexican Revolution. Second, the history of cochineal production and use in Latin America prior to colonialism and how it became monopolized by the Spaniards are overlooked. Finally, it would have been interesting to grant some attention to the resilience of cochineal production despite its decline after the second industrial revolution, since the product is still used today and somehow managed to escape its demise to some extent.\nMintz, however, offers an even more insightful analysis and it is not by chance that the book from which this chapter is taken from has become a classic, giving rise to an entire new field in anthropology, namely the anthropology of food. The argument is explained through a wide variety of anthropological concepts (intensification, extensification, outside and inside meanings…) which are interesting when applied to an economic subject such as the sugar commodity. The most powerful aspect of this text is its confrontation to some classical evidence that are omnipresent and taken for granted in economics and economic history: the naturality of sugar demand which is generally considered as given and self-evident, the important role given to price fluctuation and even to free choice and individual agency. The role of prices, meanings, demand, individual choices and liberty are carefully examined and put into question.\nUnfortunately, Mintz does not support his own thesis. He even admits at the end that his hypothesis, the success of sugar in British society as a result of structural changes in schedule, working conditions and daily life of the British workers, is “difficult or impossible to prove” (p. 186) and he regresses his argument stating that the nature of sugar must also have played a role in its success. Such contradictions are present throughout the text and tend to make difficult any attempt to clearly grasp Mintz’ arguments and positions. Another example of such contradictions is the distinctive place of sugar between “intensification” (explained above) and “extensification”, when meanings and habits are indigenous to a specific group or class and spread without imitation. Mintz states that sugar was particular in its high degree of extensification among the British masses and that the latter developed meanings towards sugar independently from the upper classes. However, Mintz does not develop further this interesting idea and his description of sugar’s meanings through literature is not sufficient and convincing enough to explain what sugar meant to the working class."
  },
  {
    "objectID": "posts/Sugar, Cochineal and Power/sugar cochineal power.html#summing-up",
    "href": "posts/Sugar, Cochineal and Power/sugar cochineal power.html#summing-up",
    "title": "Sugar, Cochineal and power",
    "section": "Summing up",
    "text": "Summing up\nTo sum up, Marichal’s book chapter on the cochineal is part of a wider project destined to put commodities back into the heart of economics and economic history. The author has three main hypothesis covering cochineal’s economic history. First, the tremendous growth in production and trade of this commodity was led by the demand of European upper classes. Second, the stability of the production process in Oaxaca was based on the repartimiento system. Finally, the decline of cochineal production and trade was the consequence of the second industrial revolution thanks to the invention of synthetic dies. Whereas cochineal is nowadays more of a relic from the past despite some relative resilience that should deserve some further attention (cochineal’s carminic acid is still used in some final products like syrup for example), sugar represents today the paroxysm of consumption under capitalism and is perhaps the most emblematic and embodiment of the commodity, as a crucial input in value chains as well as a final product. Mintz’ Sweetness and Power has since become a classic in anthropology, laying the foundation of a new field focused around the anthropology of food. I tried through this critic to show that Mintz’ argument is more than just a link between British demand for sugar and the exploitation of African slaves in the Caribbean plantations. Mintz’ analysis provides deeper investigations of the role of meanings attributed to sugar as well as for the role of both demand and supply, the political and power interests in the rise of one of nowadays’ most consumed, omnipresent, and controversial commodity."
  },
  {
    "objectID": "posts/Sugar, Cochineal and Power/sugar cochineal power.html#references",
    "href": "posts/Sugar, Cochineal and Power/sugar cochineal power.html#references",
    "title": "Sugar, Cochineal and power",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "Vote for the left in Switzerland a simple analysis/select2019analysis.html",
    "href": "Vote for the left in Switzerland a simple analysis/select2019analysis.html",
    "title": "The vote for the left in the 2015 Swiss National Council Election: a short analysis",
    "section": "",
    "text": "Two years ago, Piketty and his team published a fascinating book about the evolution of political cleavages in almost all democratic countries in the world and even beyond. The publication of this book and of its online database got me very interested in the study of political cleavages from a political economy approach. This book contains huge amount of findings and observations, but there is one which is really emphasized by the authors: from roughly the 1980s until, the class-based political divide has become a multidimensional one incorporating a “educational” or, in Inglehart terms, a “postmaterial” or “cultural” cleavage (Gethin, Martinez-Toledano, and Piketty 2021) (Inglehart 1971). Very shortly, They found that the electoral support for the left shifted from the low income and low education classes to the highly educated ones. Regarding the electoral support for the right, the latter remains positively correlated with income.\nThis post is going to simply test this finding for Switzerland using the post-electoral survey for the National Council election in 2015. The following analysis is based on data analysis of the Swiss Election Study (Selects) of 2019. The dataset can be found here. I will test if the support for the left is linked positively with the education level and negatively with income.\n\n\n\n\n\n\nTo analyze the link between vote for the left (dependent variable) and income and education, I create a dummy variable from the variable “f10300” which asked for which party the respondent voted in the 2015 election. From this variable, I create a dummy variable taking value one if the respondant voted for either the socialist party (PS), the green (PES), solidarité or Swiss labor party (PST-POP). Note that those choices can be controversial and a matter of debate because I don’t include the Social-christian party and I include the greens. This is a matter of debate if those parties can be classified as left or not, but I will not go further about this.\nRegarding the independ variables, the variable “f28910” asks the gross monthly houshold income of the individual and the variable has 15 income brackets (we thus do not have directly the income of the respondant). For education, “f21310” asks the highest level of achieved education. Here is below descriptive statistics for these variables:\n\n\n\n\n\n\n\n\n\nas_label(Education.level)\nn\n\n\n\n\nNo completed education\n16\n\n\nPrimary school\n129\n\n\nSecondary school\n275\n\n\nBasic vocational training\n85\n\n\nVocational training, apprenticeship\n2404\n\n\nDiploma school\n168\n\n\nTrading school\n410\n\n\nSecondary school vocational diploma\n307\n\n\nHigh school, school preparing for the baccalaureate\n495\n\n\nHigher vocational education with federal diploma\n861\n\n\nHigher vocational college: technical, economics, social work, etc.\n524\n\n\nUniversity of applied sciences, pedagogical university\n865\n\n\nUniversity, Federal Institute of technology\n1317\n\n\nOther\n48\n\n\nNA\n35\n\n\n\n\n\n# A tibble: 16 × 2\n   `as_label(Gross.monthly.hh.income)`     n\n   <fct>                               <int>\n 1 Less than 2'000 CHF                   542\n 2 2'001-3'000 CHF                       444\n 3 3'001-4'000 CHF                       499\n 4 4'001-5'000 CHF                       730\n 5 5'001-6'000 CHF                       810\n 6 6'001-7'000 CHF                       723\n 7 7'001-8'000 CHF                       706\n 8 8'001-9'000 CHF                       584\n 9 9'001-10'000 CHF                      482\n10 10'001-11'000 CHF                     421\n11 11'001-12'000 CHF                     361\n12 12'001-13'000 CHF                     296\n13 13'001-14'000 CHF                     222\n14 14'001-15'000 CHF                     185\n15 More than 15'000 CHF                  601\n16 <NA>                                  333\n\n\n# A tibble: 1 × 1\n      n\n  <int>\n1  7939\n\n\n\n\n\n\n\n\n\n1 = vote for a left-wing party\n\n\nvote.left\nn\nprop\n\n\n\n\n0\n5873\n0.7397657\n\n\n1\n2066\n0.2602343\n\n\n\n\n\n\n\n\n\nReferences\n\nGethin, Armory, Clara Martinez-Toledano, and Thomas Piketty. 2021. Political Cleavages and Social Inequalities a Study of Fifty Democracies, 1948–2020. Harvard Univeristy Press.\n\n\nInglehart, Ronald. 1971. “The Silent Revolution in Europe: Intergenerational Change in Post-Industrial Societies.” The American Political Science Review 65 (4): 991–1017. https://www.jstor.org/stable/1953494."
  },
  {
    "objectID": "posts/Vote for the left in Switzerland a simple analysis/select2019analysis.html",
    "href": "posts/Vote for the left in Switzerland a simple analysis/select2019analysis.html",
    "title": "The vote for the left in the 2015 Swiss National Council Election: a short analysis",
    "section": "",
    "text": "Two years ago, Piketty and his team published a fascinating book about the evolution of political cleavages in almost all democratic countries in the world and even beyond. The publication of this book and of its online database got me very interested in the study of political cleavages from a political economy approach. This book contains huge amount of findings and observations, but there is one which is really emphasized by the authors: from roughly the 1980s until, the class-based political divide has become a multidimensional one incorporating a “educational” or, in Inglehart terms, a “postmaterial” or “cultural” cleavage (Gethin, Martinez-Toledano, and Piketty 2021) (Inglehart 1971). Very shortly, They found that the electoral support for the left shifted from the low income and low education classes to the highly educated ones. Regarding the electoral support for the right, the latter remains positively correlated with income.\nThis post is going to simply test this finding for Switzerland using the post-electoral survey for the National Council election in 2015. The following analysis is based on data analysis of the Swiss Election Study (Selects) of 2019. The dataset can be found here. I will test if the support for the left is linked positively with the education level and negatively with income.\n\n\n\nTo analyze the link between vote for the left (dependent variable) and income and education, I create a dummy variable from the variable “f10300” which asked for which party the respondent voted in the 2015 election. From this variable, I create a dummy variable taking value one if the respondant voted for either the socialist party (PS), the green (PES), solidarité or Swiss labor party (PST-POP). Note that those choices can be controversial and a matter of debate because I don’t include the Social-christian party and I include the greens. This is a matter of debate if those parties can be classified as left or not, but I will not go further about this.\nRegarding the independ variables, the variable “f28910” asks the gross monthly houshold income of the individual and the variable has 15 income brackets (we thus do not have directly the income of the respondant). For education, “f21310” asks the highest level of achieved education. Here is below descriptive statistics for these variables:\n\n\n\n\n\nEducation level\n\n\n\n\n\n\n\n\n\nGross monthly houshold income"
  },
  {
    "objectID": "posts/Vote for the left in Switzerland a simple analysis/select2019analysis.html#first-model-binary-logistic-regression",
    "href": "posts/Vote for the left in Switzerland a simple analysis/select2019analysis.html#first-model-binary-logistic-regression",
    "title": "The vote for the left in the 2015 Swiss National Council Election: a short analysis",
    "section": "First model: binary logistic regression",
    "text": "First model: binary logistic regression\nLet’s first start with a logistic regression. I simply regress the vote for the left with income and education. I leave education and income coded as numerical variables for now, since they have enough categories this is not big problem. Of course, that would have been better if I had directly the income of each individual and not brackets. Moreover, I could still do a Pareto interpolation, but I can’t due to lack of information: I don’t have the average income (total and per bracket) of the sample.\nThe model is thus:\n\\[\nLog(\\frac{P(left)}{1 - P(left)}) = \\beta_0 + \\beta_1income_i + \\beta_2educ_i + \\epsilon_i\n\\]\nNote that this is a very first step, I will step by step complexify this model.\nHere is the regression table:\n\n\n\nModel 1: binary logit regression (odd ratios)\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nvote.left\n\n\n\n\n\n\n\n\nGross.monthly.hh.income\n\n\n0.926***\n\n\n\n\n\n\n(0.008)\n\n\n\n\n\n\n\n\n\n\nEducation.level\n\n\n1.125***\n\n\n\n\n\n\n(0.009)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.350***\n\n\n\n\n\n\n(0.083)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n5,607\n\n\n\n\nLog Likelihood\n\n\n-3,559.022\n\n\n\n\nAkaike Inf. Crit.\n\n\n7,124.044\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\nHere is an odd ratios plot to have a better visualization of the coefficients:\n\n\n\n\n\n\n\nHere is what this coefficient plot tells: the odds that a Swiss voter vote for a left-wing party for the National Council election of 2015 are linked negatively with income (odd ratio below 1) and positively with education (odd ratio > 1). The coefficients are statistically significant at the one percent level, which is not a surprise because the sample is rather large. Inference will become more of a problem when I consider education or even income as a factor/qualitative variable (income here is coded in brackets, so it is rather an ordinal variable, and there is to my knowledge to way to solve this problem).\nOdd ratios are known to be rather difficult to interpret. In effect, odd ratios are not what the literature calls “quantity of interest”, that is to say, the quantity of the dependent variable which is the most easy to interpret. I this model, the quantity of interest is the probability to vote for a left wing party and not the odds. A lot of economists and social scientists prefer to have a look directly at the marginal effects and predicted probability to have a better view of the relationships between the variables and of the quantity of interest.\nI first plot simple graphs of the estimated curves. To do so, I use the function Invlogit from the plot3logit package and put the estimated coefficient into this function. To do such graphs, one has to make the explanatory variable on the x axis to vary while the other explanatory variables are held constant. A choice has thus to be made about which fixed value of the other factors (of Income for the education level plot and conversely), I decided to choose the median value.\n\n\n\n\n\nProbability of voting for the left - curves from estimated coefficients\n\n\n\n\nWe can see that the slope of the education level curve is steeper than the one for income: this means that the positive link between the level of education and the probability to vote for the left is greater than the negative one for income. But let’s have a look directly at the marginal effects.\nThere are a lot of different ways to compute marginal effects, which make the latter sometimes confusing because we don’t know which type of marginal effects we are talking about. I will here consider one type of marginal effects:\n\nGroup-average marginal effects: slope estimates are produced for each row of the dataset used in computing the model. Then, the estimates can be grouped by the values of one of the regressor and the average for each group is computed.\n\nA first step in group-average marginal effects in R is to use the function “slopes” which calculate estimates of the slopes (marginal effects) for each observation used to compute the model in the first place. The term “variables” is for the variable for which the slopes are estimated and “by” the argument for\n\nmarginaleffectseduc <- slopes(reg, variables = \"Education.level\")\nhead(marginaleffectseduc)\n\n\n            Term Estimate Std. Error    z Pr(>|z|)  2.5 % 97.5 %\n Education.level   0.0233    0.00174 13.4   <0.001 0.0199 0.0267\n Education.level   0.0295    0.00231 12.8   <0.001 0.0250 0.0341\n Education.level   0.0281    0.00237 11.9   <0.001 0.0235 0.0328\n Education.level   0.0285    0.00226 12.6   <0.001 0.0241 0.0329\n Education.level   0.0238    0.00185 12.8   <0.001 0.0201 0.0274\n Education.level   0.0275    0.00209 13.2   <0.001 0.0234 0.0316\n\nColumns: rowid, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vote.left, Gross.monthly.hh.income, Education.level \n\n\n\ndim(marginaleffectseduc)\n\n[1] 5607   14\n\n\nThe dataframe has 5607 rows which is the same number of observation used in the model. We can then used the different values of income level (from 1 to 15) as grouped within which estimates are averaged:\n\nmarginaleffectseduc %>% \n  group_by(Gross.monthly.hh.income) %>% \n  summarise(mean.slopes.educ = mean(estimate),\n            conf.high = mean(conf.high), ## this is the same for the confidence interval\n            conf.low = mean(conf.low)) %>% \n  ungroup() -> game.educ\nhead(game.educ)\n\n# A tibble: 6 × 4\n  Gross.monthly.hh.income mean.slopes.educ conf.high conf.low\n  <dbl+lbl>                          <dbl>     <dbl>    <dbl>\n1 1 [Less than 2'000 CHF]           0.0279    0.0320   0.0238\n2 2 [2'001-3'000 CHF]               0.0274    0.0314   0.0235\n3 3 [3'001-4'000 CHF]               0.0271    0.0310   0.0232\n4 4 [4'001-5'000 CHF]               0.0268    0.0307   0.0230\n5 5 [5'001-6'000 CHF]               0.0267    0.0306   0.0229\n6 6 [6'001-7'000 CHF]               0.0267    0.0305   0.0228\n\n\nA plot can then be made to have a better view of the average marginal effects/slopes of education for each group of income:\n\ngame.educ %>% \n  ggplot()+\n  aes(x = Gross.monthly.hh.income, y = mean.slopes.educ)+\n  geom_point()+\n  geom_line()+\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.5)+\n  theme_bw()+\n  labs(title = \"Group-average marginal effect of education for each level of income group\")+\n  ylab(\"Slopes education\")\n\n\n\n\n\n\n\n\nThe slope of education level decreases on average with higher values of income group. This means that even if the probability to vote for the left is linked positively with education level, this link is weaker for higher income groups. However, it is not so much weaker because even though th line is downward slopping, it remains rather flat.\nNormally, the function plot_slope should produce the same graph:\n\nplot_slopes(reg, variables = \"Education.level\", by = \"Gross.monthly.hh.income\")\n\n\n\n\n\n\n\n\nLet’s do the same for income:\n\nmarginaleffectsinc <- slopes(reg, variables = \"Gross.monthly.hh.income\")\ngame.inc <- marginaleffectsinc %>% \n  group_by(Education.level) %>% \n  summarise(mean.slopes.inc = mean(estimate),\n            conf.high = mean(conf.high),\n            conf.low = mean(conf.low)) %>% \n  ungroup() -> game.inc\n\n\ngame.inc %>% \n  ggplot()+\n  aes(x = Education.level, y = mean.slopes.inc)+\n  geom_point()+\n  geom_line()+\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.5)+\n  theme_bw()+\n  labs(title = \"Group-average marginal effects of income for each level of education\")+\n  ylab(\"Slopes income\")\n\n\n\n\n\n\n\n\nHere the result is more interesting: the average marginal slope of income is negative for each education level but this average decreases with higher level of education. This implies that the probability to vote for the left is linked negatively with income group and that this negative link is strengthened by higher level of education. Rich and highly educated people have thus a very low probability to vote for the left.\nAnother way to look at the effect of the two independent variable on the probability to vote for the left is to look at the predictions.\n\npredictionseduc <- predictions(reg, variables = c(\"Education.level\", \"Gross.monthly.hh.income\"))\npredictionseduc <- predictions(reg, by = c(\"Education.level\", \"Gross.monthly.hh.income\"))\n\n\nplot_predictions(reg, condition = c(\"Education.level\", \"Gross.monthly.hh.income\"))+\n  scale_color_brewer(palette = \"Set1\")+\n  scale_fill_brewer(palette = \"Set1\")+\n  theme_bw()+\n  theme(legend.position = c(0.5, 0.7),\n        legend.background = element_blank())+\n  ylab(\"probability vote left\") -> plotpredicteduc\n\nplot_predictions(reg, condition = c(\"Gross.monthly.hh.income\", \"Education.level\"))+\n  scale_color_brewer(palette = \"Set1\")+\n  scale_fill_brewer(palette = \"Set1\")+\n  theme_bw()+\n  theme(legend.position = c(0.8, 0.8),\n        legend.background = element_blank())+\n  ylab(\"\") -> plotpredictincome\n\ncowplot::plot_grid(plotpredicteduc, plotpredictincome)\n\n\n\n\n\n\n\n\nThose plots are essentially the same the first one, but with the confidence interval and for different values of the regressor considered fixed for certain values.\nAnother way is to compute directly the average marginal effects without grouping:\n\nmarginaleffectsinc <- slopes(reg, variables = \"Gross.monthly.hh.income\")\nmarginaleffectseduc <- slopes(reg, variables = \"Education.level\")\navg_effect_summary_reg <- rbind(summary(marginaleffectsinc), summary(marginaleffectseduc))\n\navg_effect_summary_reg\n\n\n                    Term    Contrast Estimate Std. Error     z Pr(>|z|)   2.5 %\n Gross.monthly.hh.income mean(dY/dX)  -0.0171    0.00166 -10.3   <0.001 -0.0204\n Education.level         mean(dY/dX)   0.0262    0.00195  13.4   <0.001  0.0224\n  97.5 %\n -0.0139\n  0.0300\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, conf.low, conf.high \n\n\nHere is a nice way to visualize the table above:\n\navg_effect_summary_reg %>% \n  ggplot()+\n  aes(x = estimate*100, y = term)+\n  geom_vline(xintercept = 0, color = \"red\")+\n  geom_pointrange(aes(xmin = conf.low*100, xmax = conf.high*100))+\n  theme_bw()+\n  xlab(\"Average marginal effects (percentage points)\")+\n  ylab(\"\")+\n  geom_label(aes(label = round(estimate*100, 3)), nudge_y = 0.15)\n\n\n\n\n\n\n\n\nThe advantage of average marginal effects is the fact that they give information on the quantity of interest (here the probability to vote for the left) instead of odd ratio or log odds. The probability to vote for the left decreases on average by -1.715 percentage points if we compare two units which only differs by one income group level. Conversely, the probability increases on average by 2.6 percentage points if we compare two units which only differs by one level of education."
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html",
    "title": "Some Data Aanalysis and Maps with R",
    "section": "",
    "text": "What follows is a data analysis that I made for one of my master’s courses on applied methods with R"
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html#description-of-some-variables-of-the-dataset",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html#description-of-some-variables-of-the-dataset",
    "title": "Some Data Aanalysis and Maps with R",
    "section": "Description of some variables of the dataset",
    "text": "Description of some variables of the dataset\n\n\n\n\n\n\n\n\nVariable name\nShort description\nInformation\n\n\n\n\nccode\nCountry code\nCountry code with the ISO-3166-1 standard\n\n\ncname\nCountry name\nCountry name\n\n\nyear\nYear\n\n\n\nht_region\nRegion of the Country\nTenfold politico-geographic classification of world region from 1 to 10\n\n\nwdi_area\nLand area (sq.km)\nCountry’s total area excluding area under inland water bodies, exclusive economic zones and claims to continental shelf\n\n\nwdi_pop\nTotal population\nAll residents regardless of legal status or citizenship (midyear estimates)\n\n\nwdi_popden\nPopulation density\nPeople per sq. km of land area. Midyear population divided by land area in square kilometers\n\n\nbr_dem\nIs the country a democracy\nDummy variable indicator of democracy based on minimalist definition (if there is free and fair election, peaceful turnover of officers)\n\n\nbr_elect\nTypology of political institutions\nAlternative democracy indicator capturing degree of multi-party competition.\n\n\nchga_hinst\nRegime Institutions\nSix-fold classification of political regimes\n\n\nht_regtype\nRegime Type\nQualitative variable representing the political regime of each country based on 26 levels\n\n\np_polity2\nRevised Combined Polity Score\nOrdinal variable: range from -10 (strongly autocratic) to +10 (strongly democratic)\n\n\nwdi_gnicon2010\nGNI (constant 2010 US dollar)\nGross national income: sum of value added by all resident producers plus any product taxes less subsidies\n\n\nwdi_gnicapcon2010\nGNI per capital (constant 2010 US dollar)\nGNI divided by midyear population\n\n\nwdi_gdpcapcon2010\nGDP per capita (constant 2010 US dollar)\nGross domestic product divided by midyear population. GDP is the sum of gross value added by residents producers plus product taxes minus subsidies\n\n\nwdi_lifexp\nLife expectancy at birth, total (years)\nNumber of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life\n\n\nwdi_litrad\nLiteracy rate, adult total (% of people ages 15 and above)\nPercentage of the population above 15 who can understand, read and write a short simple statement\n\n\nundp_hdi\nHuman Development Index\nSummary measure of average achievement in health, knowledge and decent standards of living\n\n\nwdi_expmil\nMilitary expenditure (% of GDP)\nAll current and capital expenditures on the armed forces\n\n\nwdi_internet\nIndividuals using the Internet (% of population)\nInternet users who have used Internet in the last 3 months"
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html#recoding-the-regions",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html#recoding-the-regions",
    "title": "Some Data Aanalysis and Maps with R",
    "section": "Recoding the regions",
    "text": "Recoding the regions\n\ndata_cntr_reg %>% \n  mutate(\n    my_region = ifelse(ht_region %in% c(2, 10), \"Americas\",\n                        ifelse(cname %in% c(\"Canada\", \"United States of America (the)\"), \"Americas\",\n                          ifelse(ht_region %in% c(6, 7, 8) | cname %in% c(\"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\", \"Kazakhstan\", \"Kyrgyzstan\"), \"Asia\",\n                              ifelse(ht_region %in% c(1, 5), \"Europe\",\n                                     ifelse(ht_region == 3 | cname %in% c(\"Turkey\", \"Israel\", \"Cyprus\"), \"North Africa & Middle East (including Israel, Turkey & Cyprus)\",\n                                            ifelse(ht_region == 4, \"Sub-Saharan Africa\",\n                                                   ifelse(ht_region == 9 | cname %in% c(\"Australia\", \"New-Zealand\"), \"The Pacific (including Australia & New-Zealand\", 0)))))))\n  ) -> data_cntr_reg\n\ndata_cntr_reg %>% \n  arrange(ht_region, cname) %>% \n  kable(caption = \"Countries and their region\")\n\n\nCountries and their region\n\n\n\n\n\n\n\ncname\nht_region\nmy_region\n\n\n\n\nAlbania\n1\nEurope\n\n\nArmenia\n1\nEurope\n\n\nAzerbaijan\n1\nEurope\n\n\nBelarus\n1\nEurope\n\n\nBosnia and Herzegovina\n1\nEurope\n\n\nBulgaria\n1\nEurope\n\n\nCroatia\n1\nEurope\n\n\nCzechia\n1\nEurope\n\n\nCzechoslovakia\n1\nEurope\n\n\nEstonia\n1\nEurope\n\n\nGeorgia\n1\nEurope\n\n\nHungary\n1\nEurope\n\n\nKazakhstan\n1\nAsia\n\n\nKyrgyzstan\n1\nAsia\n\n\nLatvia\n1\nEurope\n\n\nLithuania\n1\nEurope\n\n\nMoldova (the Republic of)\n1\nEurope\n\n\nMontenegro\n1\nEurope\n\n\nNorth Macedonia\n1\nEurope\n\n\nPoland\n1\nEurope\n\n\nRomania\n1\nEurope\n\n\nRussian Federation (the)\n1\nEurope\n\n\nSerbia\n1\nEurope\n\n\nSerbia and Montenegro\n1\nEurope\n\n\nSlovakia\n1\nEurope\n\n\nSlovenia\n1\nEurope\n\n\nTajikistan\n1\nAsia\n\n\nTurkmenistan\n1\nAsia\n\n\nUSSR\n1\nEurope\n\n\nUkraine\n1\nEurope\n\n\nUzbekistan\n1\nAsia\n\n\nArgentina\n2\nAmericas\n\n\nBolivia (Plurinational State of)\n2\nAmericas\n\n\nBrazil\n2\nAmericas\n\n\nChile\n2\nAmericas\n\n\nColombia\n2\nAmericas\n\n\nCosta Rica\n2\nAmericas\n\n\nCuba\n2\nAmericas\n\n\nDominican Republic (the)\n2\nAmericas\n\n\nEcuador\n2\nAmericas\n\n\nEl Salvador\n2\nAmericas\n\n\nGuatemala\n2\nAmericas\n\n\nHaiti\n2\nAmericas\n\n\nHonduras\n2\nAmericas\n\n\nMexico\n2\nAmericas\n\n\nNicaragua\n2\nAmericas\n\n\nPanama\n2\nAmericas\n\n\nParaguay\n2\nAmericas\n\n\nPeru\n2\nAmericas\n\n\nUruguay\n2\nAmericas\n\n\nVenezuela (Bolivarian Republic of)\n2\nAmericas\n\n\nAlgeria\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nBahrain\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nCyprus\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nEgypt\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nIran (Islamic Republic of)\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nIraq\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nIsrael\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nJordan\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nKuwait\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nLebanon\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nLibya\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nMorocco\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nOman\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nQatar\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nSaudi Arabia\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nSyrian Arab Republic (the)\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nTunisia\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nTurkey\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nUnited Arab Emirates (the)\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nYemen\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nAngola\n4\nSub-Saharan Africa\n\n\nBenin\n4\nSub-Saharan Africa\n\n\nBotswana\n4\nSub-Saharan Africa\n\n\nBurkina Faso\n4\nSub-Saharan Africa\n\n\nBurundi\n4\nSub-Saharan Africa\n\n\nCabo Verde\n4\nSub-Saharan Africa\n\n\nCameroon\n4\nSub-Saharan Africa\n\n\nCentral African Republic (the)\n4\nSub-Saharan Africa\n\n\nChad\n4\nSub-Saharan Africa\n\n\nComoros (the)\n4\nSub-Saharan Africa\n\n\nCongo (the Democratic Republic of the)\n4\nSub-Saharan Africa\n\n\nCongo (the)\n4\nSub-Saharan Africa\n\n\nCôte d’Ivoire\n4\nSub-Saharan Africa\n\n\nDjibouti\n4\nSub-Saharan Africa\n\n\nEquatorial Guinea\n4\nSub-Saharan Africa\n\n\nEritrea\n4\nSub-Saharan Africa\n\n\nEswatini\n4\nSub-Saharan Africa\n\n\nEthiopia\n4\nSub-Saharan Africa\n\n\nGabon\n4\nSub-Saharan Africa\n\n\nGambia (the)\n4\nSub-Saharan Africa\n\n\nGhana\n4\nSub-Saharan Africa\n\n\nGuinea\n4\nSub-Saharan Africa\n\n\nGuinea-Bissau\n4\nSub-Saharan Africa\n\n\nKenya\n4\nSub-Saharan Africa\n\n\nLesotho\n4\nSub-Saharan Africa\n\n\nLiberia\n4\nSub-Saharan Africa\n\n\nMadagascar\n4\nSub-Saharan Africa\n\n\nMalawi\n4\nSub-Saharan Africa\n\n\nMali\n4\nSub-Saharan Africa\n\n\nMauritania\n4\nSub-Saharan Africa\n\n\nMauritius\n4\nSub-Saharan Africa\n\n\nMozambique\n4\nSub-Saharan Africa\n\n\nNamibia\n4\nSub-Saharan Africa\n\n\nNiger (the)\n4\nSub-Saharan Africa\n\n\nNigeria\n4\nSub-Saharan Africa\n\n\nRwanda\n4\nSub-Saharan Africa\n\n\nSao Tome and Principe\n4\nSub-Saharan Africa\n\n\nSenegal\n4\nSub-Saharan Africa\n\n\nSeychelles\n4\nSub-Saharan Africa\n\n\nSierra Leone\n4\nSub-Saharan Africa\n\n\nSomalia\n4\nSub-Saharan Africa\n\n\nSouth Africa\n4\nSub-Saharan Africa\n\n\nSouth Sudan\n4\nSub-Saharan Africa\n\n\nSudan (the)\n4\nSub-Saharan Africa\n\n\nTanzania, the United Republic of\n4\nSub-Saharan Africa\n\n\nTogo\n4\nSub-Saharan Africa\n\n\nUganda\n4\nSub-Saharan Africa\n\n\nZambia\n4\nSub-Saharan Africa\n\n\nZimbabwe\n4\nSub-Saharan Africa\n\n\nAndorra\n5\nEurope\n\n\nAustralia\n5\nEurope\n\n\nAustria\n5\nEurope\n\n\nBelgium\n5\nEurope\n\n\nCanada\n5\nAmericas\n\n\nDenmark\n5\nEurope\n\n\nFinland\n5\nEurope\n\n\nFrance\n5\nEurope\n\n\nGermany\n5\nEurope\n\n\nGreece\n5\nEurope\n\n\nIceland\n5\nEurope\n\n\nIreland\n5\nEurope\n\n\nItaly\n5\nEurope\n\n\nLiechtenstein\n5\nEurope\n\n\nLuxembourg\n5\nEurope\n\n\nMalta\n5\nEurope\n\n\nMonaco\n5\nEurope\n\n\nNetherlands (the)\n5\nEurope\n\n\nNew Zealand\n5\nEurope\n\n\nNorway\n5\nEurope\n\n\nPortugal\n5\nEurope\n\n\nSan Marino\n5\nEurope\n\n\nSpain\n5\nEurope\n\n\nSweden\n5\nEurope\n\n\nSwitzerland\n5\nEurope\n\n\nUnited Kingdom of Great Britain and Northern Ireland (the)\n5\nEurope\n\n\nUnited States of America (the)\n5\nAmericas\n\n\nChina\n6\nAsia\n\n\nJapan\n6\nAsia\n\n\nKorea (the Democratic People’s Republic of)\n6\nAsia\n\n\nKorea (the Republic of)\n6\nAsia\n\n\nMongolia\n6\nAsia\n\n\nTaiwan (Province of China)\n6\nAsia\n\n\nBrunei Darussalam\n7\nAsia\n\n\nCambodia\n7\nAsia\n\n\nIndonesia\n7\nAsia\n\n\nLao People’s Democratic Republic (the)\n7\nAsia\n\n\nMalaysia\n7\nAsia\n\n\nMyanmar\n7\nAsia\n\n\nPhilippines (the)\n7\nAsia\n\n\nSingapore\n7\nAsia\n\n\nThailand\n7\nAsia\n\n\nTimor-Leste\n7\nAsia\n\n\nViet Nam\n7\nAsia\n\n\nAfghanistan\n8\nAsia\n\n\nBangladesh\n8\nAsia\n\n\nBhutan\n8\nAsia\n\n\nIndia\n8\nAsia\n\n\nMaldives\n8\nAsia\n\n\nNepal\n8\nAsia\n\n\nPakistan\n8\nAsia\n\n\nSri Lanka\n8\nAsia\n\n\nTibet\n8\nAsia\n\n\nFiji\n9\nThe Pacific (including Australia & New-Zealand\n\n\nKiribati\n9\nThe Pacific (including Australia & New-Zealand\n\n\nMarshall Islands\n9\nThe Pacific (including Australia & New-Zealand\n\n\nMicronesia (Federated States of)\n9\nThe Pacific (including Australia & New-Zealand\n\n\nNauru\n9\nThe Pacific (including Australia & New-Zealand\n\n\nPalau\n9\nThe Pacific (including Australia & New-Zealand\n\n\nPapua New Guinea\n9\nThe Pacific (including Australia & New-Zealand\n\n\nSamoa\n9\nThe Pacific (including Australia & New-Zealand\n\n\nSolomon Islands\n9\nThe Pacific (including Australia & New-Zealand\n\n\nTonga\n9\nThe Pacific (including Australia & New-Zealand\n\n\nTuvalu\n9\nThe Pacific (including Australia & New-Zealand\n\n\nVanuatu\n9\nThe Pacific (including Australia & New-Zealand\n\n\nAntigua and Barbuda\n10\nAmericas\n\n\nBahamas (the)\n10\nAmericas\n\n\nBarbados\n10\nAmericas\n\n\nBelize\n10\nAmericas\n\n\nDominica\n10\nAmericas\n\n\nGrenada\n10\nAmericas\n\n\nGuyana\n10\nAmericas\n\n\nJamaica\n10\nAmericas\n\n\nSaint Kitts and Nevis\n10\nAmericas\n\n\nSaint Lucia\n10\nAmericas\n\n\nSaint Vincent and the Grenadines\n10\nAmericas\n\n\nSuriname\n10\nAmericas\n\n\nTrinidad and Tobago\n10\nAmericas\n\n\n\n\n\n\ndata_qog <- data_qog %>% \n  mutate(\n    my_region = ifelse(ht_region %in% c(2, 10), \"Americas\",\n                        ifelse(cname %in% c(\"Canada\", \"United States of America (the)\"), \"Americas\",\n                            ifelse(ht_region %in% c(6, 7, 8) | cname %in% c(\"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\", \"Kazakhstan\", \"Kyrgyzstan\"), \"Asia\",\n                              ifelse(ht_region %in% c(1, 5), \"Europe\",\n                                     ifelse(ht_region == 3 | cname %in% c(\"Turkey\", \"Israel\", \"Cyprus\"), \"North Africa & Middle East (including Israel, Turkey & Cyprus)\",\n                                            ifelse(ht_region == 4, \"Sub-Saharan Africa\",\n                                                   ifelse(ht_region == 9 | cname %in% c(\"Australia\", \"New-Zealand\"), \"The Pacific (including Australia & New-Zealand\", 0)))))))\n  )\n\n\nmy_gnicapcon2010 <- data_qog %>% \n  select(cname, wdi_pop, wdi_gnicon2010, wdi_gnicapcon2010) %>% \n  mutate(my_gnicapcon = wdi_gnicon2010/wdi_pop)\nhead(my_gnicapcon2010)\n\n# A tibble: 6 × 5\n  cname       wdi_pop wdi_gnicon2010 wdi_gnicapcon2010 my_gnicapcon\n  <chr>         <dbl>          <dbl>             <dbl>        <dbl>\n1 Afghanistan 8996967             NA                NA           NA\n2 Afghanistan 9169406             NA                NA           NA\n3 Afghanistan 9351442             NA                NA           NA\n4 Afghanistan 9543200             NA                NA           NA\n5 Afghanistan 9744772             NA                NA           NA\n6 Afghanistan 9956318             NA                NA           NA\n\n\n\ndata_gnipc <- my_gnicapcon2010 %>% \n    mutate(check = ifelse(my_gnicapcon == wdi_gnicapcon2010, 0, 1))\nhead(data_gnipc)\n\n# A tibble: 6 × 6\n  cname       wdi_pop wdi_gnicon2010 wdi_gnicapcon2010 my_gnicapcon check\n  <chr>         <dbl>          <dbl>             <dbl>        <dbl> <dbl>\n1 Afghanistan 8996967             NA                NA           NA    NA\n2 Afghanistan 9169406             NA                NA           NA    NA\n3 Afghanistan 9351442             NA                NA           NA    NA\n4 Afghanistan 9543200             NA                NA           NA    NA\n5 Afghanistan 9744772             NA                NA           NA    NA\n6 Afghanistan 9956318             NA                NA           NA    NA\n\n\n\ndata_gnipc %>% \n  count(check) %>% \n  mutate(percentage = n/sum(n)) %>% \n  kable(caption = \"check = 0: observations with same values\")\n\n\ncheck = 0: observations with same values\n\n\ncheck\nn\npercentage\n\n\n\n\n0\n219\n0.0180158\n\n\n1\n5117\n0.4209444\n\n\nNA\n6820\n0.5610398\n\n\n\n\n\nIt does not look like, when check is equal to one, that the values are different. The reason is perhaps because of how the values are rounded: observations with check = 0 have the same rounding and observations with check = 1 are rounded differently.\nLet’s adjust the check by rounding all observations to the third decimal:\n\ndata_gnipc <- data_gnipc %>% \n  mutate(check2 = ifelse(round(my_gnicapcon, digits = 3) == round(wdi_gnicapcon2010, digits = 3), 0, 1))\n\nI now check doing a table:\n\ndata_gnipc %>% \n  count(check2) %>% \n  kable(caption = \"check2 = 0: observations with same values\")\n\n\ncheck2 = 0: observations with same values\n\n\ncheck2\nn\n\n\n\n\n0\n5155\n\n\n1\n181\n\n\nNA\n6820"
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html#analysis-of-variable-life-expectancy-across-countries-and-time-wdi_lifexp",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with r.html#analysis-of-variable-life-expectancy-across-countries-and-time-wdi_lifexp",
    "title": "Some Data Aanalysis and Maps with R",
    "section": "Analysis of variable life expectancy across countries and time (wdi_lifexp)",
    "text": "Analysis of variable life expectancy across countries and time (wdi_lifexp)\nWe want: mean, median, range, variance, sd, IQR and percentage of NA for all dataset\n\ndata_qog %>% \n  summarize(\n    mean_life_exp = mean(wdi_lifexp, na.rm = TRUE),\n    median_life_exp = median(wdi_lifexp, na.rm = TRUE),\n    variance_life_exp = sd(wdi_lifexp, na.rm = TRUE)^2,\n    standard_deviation_life_exp = sd(wdi_lifexp, na.rm = TRUE),\n    IQR_life_exp = IQR(wdi_lifexp, na.rm = TRUE),\n    min_life_exp = min(wdi_lifexp, na.rm = TRUE),\n    max_life_exp = max(wdi_lifexp, na.rm = TRUE)\n  ) %>% \n  kable(caption = \"Descriptive statistics of wdi_lifexp\")\n\n\nDescriptive statistics of wdi_lifexp\n\n\n\n\n\n\n\n\n\n\n\nmean_life_exp\nmedian_life_exp\nvariance_life_exp\nstandard_deviation_life_exp\nIQR_life_exp\nmin_life_exp\nmax_life_exp\n\n\n\n\n64.31728\n67.4765\n130.9105\n11.44161\n17.30323\n18.907\n85.41707\n\n\n\n\n\n\nPercentage of NAs\n\ndata_qog %>% \n  select(wdi_lifexp) %>% \n  count(is.na(wdi_lifexp)) %>% \n  mutate(percentage_NAs = n/sum(n)) %>% \n  kable(caption = \"NAs of wdi_lifexp\")\n\n\nNAs of wdi_lifexp\n\n\nis.na(wdi_lifexp)\nn\npercentage_NAs\n\n\n\n\nFALSE\n9460\n0.7782165\n\n\nTRUE\n2696\n0.2217835\n\n\n\n\n\n\ndata_qog %>% \n  group_by(year) %>% \n  summarize(average_wdi_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() -> Q20_tibble\nhead(Q20_tibble)\n\n# A tibble: 6 × 2\n   year average_wdi_lifexp\n  <dbl>              <dbl>\n1  1960               55.4\n2  1961               53.7\n3  1962               54.1\n4  1963               54.3\n5  1964               54.6\n6  1965               54.8\n\n\n\n\nPlotting average wdi_lifexp with year\n\ndata_qog %>% \n  group_by(year) %>% \n  summarize(average_wdi_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() %>% \n  ggplot()+\n  aes(x = year, y = average_wdi_lifexp)+\n  geom_point()+\n  geom_line()+\n  theme_minimal()+\n  labs(title = \"Average life expectancy at birth\",\n       caption = \"Average number of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life\")\n\n\n\n\n\n\n\n\n\ndata_qog %>% \n  group_by(my_region, year) %>% \n  summarize(average_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() -> Q21_tibble\n\n\ndata_qog %>% \n  group_by(my_region, year) %>% \n  summarize(average_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() %>% \n  ggplot()+\n  aes(x = year, y = average_lifexp, color = my_region, shape = my_region)+\n  geom_line()+\n  geom_point(size = 1)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Average life expectancy at birth\",\n       caption = \"Average number of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life\")\n\n\n\n\n\n\n\n\n\ndata_qog %>% \n  ggplot()+\n  aes(x = wdi_gdpcapcon2010, y = wdi_lifexp)+\n  geom_point(alpha = 0.5)+\n  theme_minimal()+\n  labs(title = \"Life expectancy and GDP per capita across countries and time\")+\n  xlab(\"GDP per capita\")+\n  ylab(\"Life expectancy\")\n\n\n\n\n\n\n\n\nThere seems to be a positive correlation between GDP per cap and life expectancy.\n\ndata_qog %>% \n  ggplot()+\n  aes(x = wdi_gdpcapcon2010, y = wdi_lifexp, color = my_region)+\n  geom_point(alpha = 1)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")+\n  scale_color_brewer(palette = \"Set1\")+\n  labs(title = \"Life expectancy and GDP per capital across countries and time\")+\n   xlab(\"GDP per capita\")+\n  ylab(\"Life expectancy\")\n\n\n\n\n\n\n\n\n\nRegion with low GDP per cap and low life expectancy tends to be Sub-Saharan Africa\nRegions with high GDP per cap and high life expectancy tend to be Europe and America\nRegions for which life expectancy tend to be relatively lower than their GDP per cap is North Africa & Middle East and some countries of Sub-Saharan Africa\n\nNorth Africa and Middle East is an interesting case whose observations stand out in the graph above. Around 50000 gdp per cap, life expectancy seems to even decrease with gdp per cap. Thus, I am going to include several variable to see any pattern.\nI reproduce the graph by adding two variables: br_dem and wdi_expmil, my guess is that countries which are democratic and with few military expenditures are expected to have high GDP PC and high life expectancy (for example because less money in invested in the military and more in health care) and conversely. I expect the countries which had a declining trend in the previous graph to have relatively high military expenditure. I also add lines aesthetics to distinguish countries within the regions.\n\ndata_qog %>%  \n  ggplot()+\n  aes(x = wdi_gdpcapcon2010, y = wdi_lifexp, color = my_region, shape = factor(br_dem), size = wdi_expmil)+\n  geom_line(aes(x = wdi_gdpcapcon2010, y = wdi_lifexp, fill = cname, color = my_region), inherit.aes = FALSE)+\n  geom_point(alpha = 0.9)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")+\n  scale_color_brewer(palette = \"Set1\")+\n  scale_size_continuous(name = \"Military expenditure % of GDP\",\n                        range = c(0, 15))+\n  scale_shape_discrete(name = \"Is country democratic\")+\n  labs(title = \"Life expectancy and GDP per capital across countries and time\")+\n  xlab(\"GDP per capita\")+\n  ylab(\"Life expectancy\")\n\n\n\n\n\n\n\n\nI can see now that European countries tend to have relatively low military expenditure, have a posititve correlation between life expectancy and GDP per capita and tend to be democratic. Sub-Saharan Africa countries tend to have increasing life expectancy over the years, but no important GDP per capita growth. For Asia, There is also a positive correlation between life expectancy and gdp per cap, except for one country. The difference with Europe is that some Asian countries are not democratic (circle = non democratic). North Africa and Middle East is the most intriguing case, with a non democratic country with very high military expenditure and high fluctuation of life expectancy and another non democratic country with negative correlation between life expectancy and GDP per cap.\n\ntypeof(data_qog$br_dem)\n\n[1] \"double\"\n\ntypeof(data_qog$p_polity2)\n\n[1] \"double\"\n\nrange(data_qog$p_polity2, na.rm = TRUE)\n\n[1] -10  10\n\n\nbr_dem (is the country a democracy) is stored as a double, it is however a dummy variable (nominal variable) taking value 0 is country is not democratic and 1 if country is a democracy. Thus, it does not make sense to compute its mean, I should make a table with the frequencies or relative frequencies or do a barplot.\np_polity2 is also stored as a double. It also does not make sense because p_polity2 (revised combined polity score) is an ordinal variable ranging from -10 (strongly autocratic) to +10 (strongly democratic). To give information about this variable, I would do a table and a barplot (sorted according to the range).\nI first transform those two variables into factors\n\ndata_qog$br_dem <- factor(data_qog$br_dem, levels = c(0,1), labels = c(\"Not democratic\", \"democratic\"))\n\ndata_qog$p_polity2 <- factor(data_qog$p_polity2, levels = (-10:10))\n\nI then do some univariate and bivariate analysis of the variables through tables and a cross table\n\ndata_qog %>%\n  count(p_polity2) %>% \n  kable(caption = \"Is the country democratic\", align = \"c\")\n\n\nIs the country democratic\n\n\np_polity2\nn\n\n\n\n\n-10\n287\n\n\n-9\n606\n\n\n-8\n328\n\n\n-7\n1311\n\n\n-6\n419\n\n\n-5\n190\n\n\n-4\n231\n\n\n-3\n240\n\n\n-2\n148\n\n\n-1\n177\n\n\n0\n224\n\n\n1\n114\n\n\n2\n95\n\n\n3\n123\n\n\n4\n252\n\n\n5\n334\n\n\n6\n469\n\n\n7\n386\n\n\n8\n593\n\n\n9\n516\n\n\n10\n1577\n\n\nNA\n3536\n\n\n\n\ndata_qog %>% \n  count(br_dem) %>%\n  kable(caption = \"Is the country democratic\", align = \"c\")\n\n\nIs the country democratic\n\n\nbr_dem\nn\n\n\n\n\nNot democratic\n5140\n\n\ndemocratic\n4915\n\n\nNA\n2101\n\n\n\n\nkable(table(data_qog$p_polity2, data_qog$br_dem), caption = \"Revised combined polity score according to democracy or not\")\n\n\nRevised combined polity score according to democracy or not\n\n\n\nNot democratic\ndemocratic\n\n\n\n\n-10\n287\n0\n\n\n-9\n577\n0\n\n\n-8\n311\n0\n\n\n-7\n1206\n9\n\n\n-6\n406\n5\n\n\n-5\n155\n20\n\n\n-4\n229\n1\n\n\n-3\n209\n26\n\n\n-2\n145\n2\n\n\n-1\n164\n13\n\n\n0\n208\n11\n\n\n1\n91\n23\n\n\n2\n74\n21\n\n\n3\n77\n46\n\n\n4\n127\n125\n\n\n5\n101\n233\n\n\n6\n139\n327\n\n\n7\n41\n339\n\n\n8\n48\n545\n\n\n9\n43\n473\n\n\n10\n8\n1569\n\n\n\n\n\nI choose then to do a mosaic plot of p_polity according to br_dem to represent the association of the two variable visually\n\ndata_qog %>%\n  ggplot()+\n  geom_mosaic(aes(x = product(br_dem, p_polity2), fill = br_dem), na.rm = TRUE)+\n  theme_minimal()+\n  scale_fill_brewer(palette = \"Set1\", name = \"\")+\n  ylab(\"\")+\n  xlab(\"Revised Combined Polity Score: from -10 (strongly authocratic) to 10 (strongly democratic)\")+\n  ggtitle(\"Revised Combined Polity Score and democracy\")\n\n\n\n\n\n\n\n\nI can see that as the Revised Combined Polity Score index on the x axis increases, countries tend to be democratic. The value 4 of Revised Combined Polity Score index seems to be the turning point: before this value, there are more non democratic countries, after the value (4), most of the countries are democratic. However, there still are not democratic countries that have high revised combined polity score, which implies that there is some “disagreement” between the two variable and their definition of what a democracy is (at least for some countries).\nAnother possiblity is to do a stacked or dodge barplot of p_polity and br_dem\n\ndata_qog %>% \n  drop_na() %>% \n  ggplot()+\n  aes(x = p_polity2, y = (..count..)/sum(..count..), fill = br_dem)+\n  geom_bar(position = \"dodge\")+\n  scale_fill_brewer(palette = \"Set1\", name = \"\")+\n  ylab(\"\")+\n  xlab(\"Revised Combined Polity Score from -10 (strongly authocratic) to 10 (strongly democratic)\")+\n  theme_minimal()\n\n\n\n\n\n\n\ndata_qog %>% \n  drop_na() %>% \n  ggplot()+\n  aes(x = p_polity2, y = (..count..)/sum(..count..), fill = br_dem)+\n  geom_bar()+\n  scale_fill_brewer(palette = \"Set1\", name = \"\")+\n  ylab(\"\")+\n  xlab(\"Revised Combined Polity Score from -10 (strongly authocratic) to 10 (strongly democratic)\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\nMy analysis is here the same as the previous graph."
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html",
    "title": "Some R studio drill and how to do maps",
    "section": "",
    "text": "What follows is a short demonstration on how to do chloropleth map in R studio. What follows was part a bonus task of a practical of one of my master’s courses on applied methods with R. I tried to do some maps and the result was good despite the fact that It can take a long time to figure out how to do. This post is thus for anyone who wants to see how maps can be done on R studio without wasting too much time."
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html#description-of-some-variables-of-the-dataset",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html#description-of-some-variables-of-the-dataset",
    "title": "Some R studio drill and how to do maps",
    "section": "Description of some variables of the dataset",
    "text": "Description of some variables of the dataset\n\n\n\n\n\n\n\n\nVariable name\nShort description\nInformation\n\n\n\n\nccode\nCountry code\nCountry code with the ISO-3166-1 standard\n\n\ncname\nCountry name\nCountry name\n\n\nyear\nYear\n\n\n\nht_region\nRegion of the Country\nTenfold politico-geographic classification of world region from 1 to 10\n\n\nwdi_area\nLand area (sq.km)\nCountry’s total area excluding area under inland water bodies, exclusive economic zones and claims to continental shelf\n\n\nwdi_pop\nTotal population\nAll residents regardless of legal status or citizenship (midyear estimates)\n\n\nwdi_popden\nPopulation density\nPeople per sq. km of land area. Midyear population divided by land area in square kilometers\n\n\nbr_dem\nIs the country a democracy\nDummy variable indicator of democracy based on minimalist definition (if there is free and fair election, peaceful turnover of officers)\n\n\nbr_elect\nTypology of political institutions\nAlternative democracy indicator capturing degree of multi-party competition.\n\n\nchga_hinst\nRegime Institutions\nSix-fold classification of political regimes\n\n\nht_regtype\nRegime Type\nQualitative variable representing the political regime of each country based on 26 levels\n\n\np_polity2\nRevised Combined Polity Score\nOrdinal variable: range from -10 (strongly autocratic) to +10 (strongly democratic)\n\n\nwdi_gnicon2010\nGNI (constant 2010 US dollar)\nGross national income: sum of value added by all resident producers plus any product taxes less subsidies\n\n\nwdi_gnicapcon2010\nGNI per capital (constant 2010 US dollar)\nGNI divided by midyear population\n\n\nwdi_gdpcapcon2010\nGDP per capita (constant 2010 US dollar)\nGross domestic product divided by midyear population. GDP is the sum of gross value added by residents producers plus product taxes minus subsidies\n\n\nwdi_lifexp\nLife expectancy at birth, total (years)\nNumber of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life\n\n\nwdi_litrad\nLiteracy rate, adult total (% of people ages 15 and above)\nPercentage of the population above 15 who can understand, read and write a short simple statement\n\n\nundp_hdi\nHuman Development Index\nSummary measure of average achievement in health, knowledge and decent standards of living\n\n\nwdi_expmil\nMilitary expenditure (% of GDP)\nAll current and capital expenditures on the armed forces\n\n\nwdi_internet\nIndividuals using the Internet (% of population)\nInternet users who have used Internet in the last 3 months"
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html#recoding-the-regions",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html#recoding-the-regions",
    "title": "Some Data Aanalysis and Maps with R",
    "section": "Recoding the regions",
    "text": "Recoding the regions\n\ndata_cntr_reg %>% \n  mutate(\n    my_region = ifelse(ht_region %in% c(2, 10), \"Americas\",\n                        ifelse(cname %in% c(\"Canada\", \"United States of America (the)\"), \"Americas\",\n                          ifelse(ht_region %in% c(6, 7, 8) | cname %in% c(\"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\", \"Kazakhstan\", \"Kyrgyzstan\"), \"Asia\",\n                              ifelse(ht_region %in% c(1, 5), \"Europe\",\n                                     ifelse(ht_region == 3 | cname %in% c(\"Turkey\", \"Israel\", \"Cyprus\"), \"North Africa & Middle East (including Israel, Turkey & Cyprus)\",\n                                            ifelse(ht_region == 4, \"Sub-Saharan Africa\",\n                                                   ifelse(ht_region == 9 | cname %in% c(\"Australia\", \"New-Zealand\"), \"The Pacific (including Australia & New-Zealand\", 0)))))))\n  ) -> data_cntr_reg\n\ndata_cntr_reg %>% \n  arrange(ht_region, cname) %>% \n  kable(caption = \"Countries and their region\")\n\n\nCountries and their region\n\n\n\n\n\n\n\ncname\nht_region\nmy_region\n\n\n\n\nAlbania\n1\nEurope\n\n\nArmenia\n1\nEurope\n\n\nAzerbaijan\n1\nEurope\n\n\nBelarus\n1\nEurope\n\n\nBosnia and Herzegovina\n1\nEurope\n\n\nBulgaria\n1\nEurope\n\n\nCroatia\n1\nEurope\n\n\nCzechia\n1\nEurope\n\n\nCzechoslovakia\n1\nEurope\n\n\nEstonia\n1\nEurope\n\n\nGeorgia\n1\nEurope\n\n\nHungary\n1\nEurope\n\n\nKazakhstan\n1\nAsia\n\n\nKyrgyzstan\n1\nAsia\n\n\nLatvia\n1\nEurope\n\n\nLithuania\n1\nEurope\n\n\nMoldova (the Republic of)\n1\nEurope\n\n\nMontenegro\n1\nEurope\n\n\nNorth Macedonia\n1\nEurope\n\n\nPoland\n1\nEurope\n\n\nRomania\n1\nEurope\n\n\nRussian Federation (the)\n1\nEurope\n\n\nSerbia\n1\nEurope\n\n\nSerbia and Montenegro\n1\nEurope\n\n\nSlovakia\n1\nEurope\n\n\nSlovenia\n1\nEurope\n\n\nTajikistan\n1\nAsia\n\n\nTurkmenistan\n1\nAsia\n\n\nUSSR\n1\nEurope\n\n\nUkraine\n1\nEurope\n\n\nUzbekistan\n1\nAsia\n\n\nArgentina\n2\nAmericas\n\n\nBolivia (Plurinational State of)\n2\nAmericas\n\n\nBrazil\n2\nAmericas\n\n\nChile\n2\nAmericas\n\n\nColombia\n2\nAmericas\n\n\nCosta Rica\n2\nAmericas\n\n\nCuba\n2\nAmericas\n\n\nDominican Republic (the)\n2\nAmericas\n\n\nEcuador\n2\nAmericas\n\n\nEl Salvador\n2\nAmericas\n\n\nGuatemala\n2\nAmericas\n\n\nHaiti\n2\nAmericas\n\n\nHonduras\n2\nAmericas\n\n\nMexico\n2\nAmericas\n\n\nNicaragua\n2\nAmericas\n\n\nPanama\n2\nAmericas\n\n\nParaguay\n2\nAmericas\n\n\nPeru\n2\nAmericas\n\n\nUruguay\n2\nAmericas\n\n\nVenezuela (Bolivarian Republic of)\n2\nAmericas\n\n\nAlgeria\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nBahrain\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nCyprus\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nEgypt\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nIran (Islamic Republic of)\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nIraq\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nIsrael\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nJordan\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nKuwait\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nLebanon\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nLibya\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nMorocco\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nOman\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nQatar\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nSaudi Arabia\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nSyrian Arab Republic (the)\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nTunisia\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nTurkey\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nUnited Arab Emirates (the)\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nYemen\n3\nNorth Africa & Middle East (including Israel, Turkey & Cyprus)\n\n\nAngola\n4\nSub-Saharan Africa\n\n\nBenin\n4\nSub-Saharan Africa\n\n\nBotswana\n4\nSub-Saharan Africa\n\n\nBurkina Faso\n4\nSub-Saharan Africa\n\n\nBurundi\n4\nSub-Saharan Africa\n\n\nCabo Verde\n4\nSub-Saharan Africa\n\n\nCameroon\n4\nSub-Saharan Africa\n\n\nCentral African Republic (the)\n4\nSub-Saharan Africa\n\n\nChad\n4\nSub-Saharan Africa\n\n\nComoros (the)\n4\nSub-Saharan Africa\n\n\nCongo (the Democratic Republic of the)\n4\nSub-Saharan Africa\n\n\nCongo (the)\n4\nSub-Saharan Africa\n\n\nCôte d’Ivoire\n4\nSub-Saharan Africa\n\n\nDjibouti\n4\nSub-Saharan Africa\n\n\nEquatorial Guinea\n4\nSub-Saharan Africa\n\n\nEritrea\n4\nSub-Saharan Africa\n\n\nEswatini\n4\nSub-Saharan Africa\n\n\nEthiopia\n4\nSub-Saharan Africa\n\n\nGabon\n4\nSub-Saharan Africa\n\n\nGambia (the)\n4\nSub-Saharan Africa\n\n\nGhana\n4\nSub-Saharan Africa\n\n\nGuinea\n4\nSub-Saharan Africa\n\n\nGuinea-Bissau\n4\nSub-Saharan Africa\n\n\nKenya\n4\nSub-Saharan Africa\n\n\nLesotho\n4\nSub-Saharan Africa\n\n\nLiberia\n4\nSub-Saharan Africa\n\n\nMadagascar\n4\nSub-Saharan Africa\n\n\nMalawi\n4\nSub-Saharan Africa\n\n\nMali\n4\nSub-Saharan Africa\n\n\nMauritania\n4\nSub-Saharan Africa\n\n\nMauritius\n4\nSub-Saharan Africa\n\n\nMozambique\n4\nSub-Saharan Africa\n\n\nNamibia\n4\nSub-Saharan Africa\n\n\nNiger (the)\n4\nSub-Saharan Africa\n\n\nNigeria\n4\nSub-Saharan Africa\n\n\nRwanda\n4\nSub-Saharan Africa\n\n\nSao Tome and Principe\n4\nSub-Saharan Africa\n\n\nSenegal\n4\nSub-Saharan Africa\n\n\nSeychelles\n4\nSub-Saharan Africa\n\n\nSierra Leone\n4\nSub-Saharan Africa\n\n\nSomalia\n4\nSub-Saharan Africa\n\n\nSouth Africa\n4\nSub-Saharan Africa\n\n\nSouth Sudan\n4\nSub-Saharan Africa\n\n\nSudan (the)\n4\nSub-Saharan Africa\n\n\nTanzania, the United Republic of\n4\nSub-Saharan Africa\n\n\nTogo\n4\nSub-Saharan Africa\n\n\nUganda\n4\nSub-Saharan Africa\n\n\nZambia\n4\nSub-Saharan Africa\n\n\nZimbabwe\n4\nSub-Saharan Africa\n\n\nAndorra\n5\nEurope\n\n\nAustralia\n5\nEurope\n\n\nAustria\n5\nEurope\n\n\nBelgium\n5\nEurope\n\n\nCanada\n5\nAmericas\n\n\nDenmark\n5\nEurope\n\n\nFinland\n5\nEurope\n\n\nFrance\n5\nEurope\n\n\nGermany\n5\nEurope\n\n\nGreece\n5\nEurope\n\n\nIceland\n5\nEurope\n\n\nIreland\n5\nEurope\n\n\nItaly\n5\nEurope\n\n\nLiechtenstein\n5\nEurope\n\n\nLuxembourg\n5\nEurope\n\n\nMalta\n5\nEurope\n\n\nMonaco\n5\nEurope\n\n\nNetherlands (the)\n5\nEurope\n\n\nNew Zealand\n5\nEurope\n\n\nNorway\n5\nEurope\n\n\nPortugal\n5\nEurope\n\n\nSan Marino\n5\nEurope\n\n\nSpain\n5\nEurope\n\n\nSweden\n5\nEurope\n\n\nSwitzerland\n5\nEurope\n\n\nUnited Kingdom of Great Britain and Northern Ireland (the)\n5\nEurope\n\n\nUnited States of America (the)\n5\nAmericas\n\n\nChina\n6\nAsia\n\n\nJapan\n6\nAsia\n\n\nKorea (the Democratic People’s Republic of)\n6\nAsia\n\n\nKorea (the Republic of)\n6\nAsia\n\n\nMongolia\n6\nAsia\n\n\nTaiwan (Province of China)\n6\nAsia\n\n\nBrunei Darussalam\n7\nAsia\n\n\nCambodia\n7\nAsia\n\n\nIndonesia\n7\nAsia\n\n\nLao People’s Democratic Republic (the)\n7\nAsia\n\n\nMalaysia\n7\nAsia\n\n\nMyanmar\n7\nAsia\n\n\nPhilippines (the)\n7\nAsia\n\n\nSingapore\n7\nAsia\n\n\nThailand\n7\nAsia\n\n\nTimor-Leste\n7\nAsia\n\n\nViet Nam\n7\nAsia\n\n\nAfghanistan\n8\nAsia\n\n\nBangladesh\n8\nAsia\n\n\nBhutan\n8\nAsia\n\n\nIndia\n8\nAsia\n\n\nMaldives\n8\nAsia\n\n\nNepal\n8\nAsia\n\n\nPakistan\n8\nAsia\n\n\nSri Lanka\n8\nAsia\n\n\nTibet\n8\nAsia\n\n\nFiji\n9\nThe Pacific (including Australia & New-Zealand\n\n\nKiribati\n9\nThe Pacific (including Australia & New-Zealand\n\n\nMarshall Islands\n9\nThe Pacific (including Australia & New-Zealand\n\n\nMicronesia (Federated States of)\n9\nThe Pacific (including Australia & New-Zealand\n\n\nNauru\n9\nThe Pacific (including Australia & New-Zealand\n\n\nPalau\n9\nThe Pacific (including Australia & New-Zealand\n\n\nPapua New Guinea\n9\nThe Pacific (including Australia & New-Zealand\n\n\nSamoa\n9\nThe Pacific (including Australia & New-Zealand\n\n\nSolomon Islands\n9\nThe Pacific (including Australia & New-Zealand\n\n\nTonga\n9\nThe Pacific (including Australia & New-Zealand\n\n\nTuvalu\n9\nThe Pacific (including Australia & New-Zealand\n\n\nVanuatu\n9\nThe Pacific (including Australia & New-Zealand\n\n\nAntigua and Barbuda\n10\nAmericas\n\n\nBahamas (the)\n10\nAmericas\n\n\nBarbados\n10\nAmericas\n\n\nBelize\n10\nAmericas\n\n\nDominica\n10\nAmericas\n\n\nGrenada\n10\nAmericas\n\n\nGuyana\n10\nAmericas\n\n\nJamaica\n10\nAmericas\n\n\nSaint Kitts and Nevis\n10\nAmericas\n\n\nSaint Lucia\n10\nAmericas\n\n\nSaint Vincent and the Grenadines\n10\nAmericas\n\n\nSuriname\n10\nAmericas\n\n\nTrinidad and Tobago\n10\nAmericas\n\n\n\n\n\n\ndata_qog <- data_qog %>% \n  mutate(\n    my_region = ifelse(ht_region %in% c(2, 10), \"Americas\",\n                        ifelse(cname %in% c(\"Canada\", \"United States of America (the)\"), \"Americas\",\n                            ifelse(ht_region %in% c(6, 7, 8) | cname %in% c(\"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\", \"Kazakhstan\", \"Kyrgyzstan\"), \"Asia\",\n                              ifelse(ht_region %in% c(1, 5), \"Europe\",\n                                     ifelse(ht_region == 3 | cname %in% c(\"Turkey\", \"Israel\", \"Cyprus\"), \"North Africa & Middle East (including Israel, Turkey & Cyprus)\",\n                                            ifelse(ht_region == 4, \"Sub-Saharan Africa\",\n                                                   ifelse(ht_region == 9 | cname %in% c(\"Australia\", \"New-Zealand\"), \"The Pacific (including Australia & New-Zealand\", 0)))))))\n  )\n\n\nmy_gnicapcon2010 <- data_qog %>% \n  select(cname, wdi_pop, wdi_gnicon2010, wdi_gnicapcon2010) %>% \n  mutate(my_gnicapcon = wdi_gnicon2010/wdi_pop)\nhead(my_gnicapcon2010)\n\n# A tibble: 6 × 5\n  cname       wdi_pop wdi_gnicon2010 wdi_gnicapcon2010 my_gnicapcon\n  <chr>         <dbl>          <dbl>             <dbl>        <dbl>\n1 Afghanistan 8996967             NA                NA           NA\n2 Afghanistan 9169406             NA                NA           NA\n3 Afghanistan 9351442             NA                NA           NA\n4 Afghanistan 9543200             NA                NA           NA\n5 Afghanistan 9744772             NA                NA           NA\n6 Afghanistan 9956318             NA                NA           NA\n\n\n\ndata_gnipc <- my_gnicapcon2010 %>% \n    mutate(check = ifelse(my_gnicapcon == wdi_gnicapcon2010, 0, 1))\nhead(data_gnipc)\n\n# A tibble: 6 × 6\n  cname       wdi_pop wdi_gnicon2010 wdi_gnicapcon2010 my_gnicapcon check\n  <chr>         <dbl>          <dbl>             <dbl>        <dbl> <dbl>\n1 Afghanistan 8996967             NA                NA           NA    NA\n2 Afghanistan 9169406             NA                NA           NA    NA\n3 Afghanistan 9351442             NA                NA           NA    NA\n4 Afghanistan 9543200             NA                NA           NA    NA\n5 Afghanistan 9744772             NA                NA           NA    NA\n6 Afghanistan 9956318             NA                NA           NA    NA\n\n\n\ndata_gnipc %>% \n  count(check) %>% \n  mutate(percentage = n/sum(n)) %>% \n  kable(caption = \"check = 0: observations with same values\")\n\n\ncheck = 0: observations with same values\n\n\ncheck\nn\npercentage\n\n\n\n\n0\n219\n0.0180158\n\n\n1\n5117\n0.4209444\n\n\nNA\n6820\n0.5610398\n\n\n\n\n\nIt does not look like, when check is equal to one, that the values are different. The reason is perhaps because of how the values are rounded: observations with check = 0 have the same rounding and observations with check = 1 are rounded differently.\nLet’s adjust the check by rounding all observations to the third decimal:\n\ndata_gnipc <- data_gnipc %>% \n  mutate(check2 = ifelse(round(my_gnicapcon, digits = 3) == round(wdi_gnicapcon2010, digits = 3), 0, 1))\n\nI now check doing a table:\n\ndata_gnipc %>% \n  count(check2) %>% \n  kable(caption = \"check2 = 0: observations with same values\")\n\n\ncheck2 = 0: observations with same values\n\n\ncheck2\nn\n\n\n\n\n0\n5155\n\n\n1\n181\n\n\nNA\n6820"
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html#analysis-of-variable-life-expectancy-across-countries-and-time-wdi_lifexp",
    "href": "posts/Some data analysis and how to do a map with r/Some data analysis and maps with R.html#analysis-of-variable-life-expectancy-across-countries-and-time-wdi_lifexp",
    "title": "Some Data Aanalysis and Maps with R",
    "section": "Analysis of variable life expectancy across countries and time (wdi_lifexp)",
    "text": "Analysis of variable life expectancy across countries and time (wdi_lifexp)\nWe want: mean, median, range, variance, sd, IQR and percentage of NA for all dataset\n\ndata_qog %>% \n  summarize(\n    mean_life_exp = mean(wdi_lifexp, na.rm = TRUE),\n    median_life_exp = median(wdi_lifexp, na.rm = TRUE),\n    variance_life_exp = sd(wdi_lifexp, na.rm = TRUE)^2,\n    standard_deviation_life_exp = sd(wdi_lifexp, na.rm = TRUE),\n    IQR_life_exp = IQR(wdi_lifexp, na.rm = TRUE),\n    min_life_exp = min(wdi_lifexp, na.rm = TRUE),\n    max_life_exp = max(wdi_lifexp, na.rm = TRUE)\n  ) %>% \n  kable(caption = \"Descriptive statistics of wdi_lifexp\")\n\n\nDescriptive statistics of wdi_lifexp\n\n\n\n\n\n\n\n\n\n\n\nmean_life_exp\nmedian_life_exp\nvariance_life_exp\nstandard_deviation_life_exp\nIQR_life_exp\nmin_life_exp\nmax_life_exp\n\n\n\n\n64.31728\n67.4765\n130.9105\n11.44161\n17.30323\n18.907\n85.41707\n\n\n\n\n\n\nPercentage of NAs\n\ndata_qog %>% \n  select(wdi_lifexp) %>% \n  count(is.na(wdi_lifexp)) %>% \n  mutate(percentage_NAs = n/sum(n)) %>% \n  kable(caption = \"NAs of wdi_lifexp\")\n\n\nNAs of wdi_lifexp\n\n\nis.na(wdi_lifexp)\nn\npercentage_NAs\n\n\n\n\nFALSE\n9460\n0.7782165\n\n\nTRUE\n2696\n0.2217835\n\n\n\n\n\n\ndata_qog %>% \n  group_by(year) %>% \n  summarize(average_wdi_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() -> Q20_tibble\nhead(Q20_tibble)\n\n# A tibble: 6 × 2\n   year average_wdi_lifexp\n  <dbl>              <dbl>\n1  1960               55.4\n2  1961               53.7\n3  1962               54.1\n4  1963               54.3\n5  1964               54.6\n6  1965               54.8\n\n\n\n\nPlotting average wdi_lifexp with year\n\ndata_qog %>% \n  group_by(year) %>% \n  summarize(average_wdi_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() %>% \n  ggplot()+\n  aes(x = year, y = average_wdi_lifexp)+\n  geom_point()+\n  geom_line()+\n  theme_minimal()+\n  labs(title = \"Average life expectancy at birth\",\n       caption = \"Average number of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life\")\n\n\n\n\n\n\n\n\n\ndata_qog %>% \n  group_by(my_region, year) %>% \n  summarize(average_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() -> Q21_tibble\n\n\ndata_qog %>% \n  group_by(my_region, year) %>% \n  summarize(average_lifexp = mean(wdi_lifexp, na.rm = TRUE)) %>% \n  ungroup() %>% \n  ggplot()+\n  aes(x = year, y = average_lifexp, color = my_region, shape = my_region)+\n  geom_line()+\n  geom_point(size = 1)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Average life expectancy at birth\",\n       caption = \"Average number of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life\")\n\n\n\n\n\n\n\n\n\ndata_qog %>% \n  ggplot()+\n  aes(x = wdi_gdpcapcon2010, y = wdi_lifexp)+\n  geom_point(alpha = 0.5)+\n  theme_minimal()+\n  labs(title = \"Life expectancy and GDP per capita across countries and time\")+\n  xlab(\"GDP per capita\")+\n  ylab(\"Life expectancy\")\n\n\n\n\n\n\n\n\nThere seems to be a positive correlation between GDP per cap and life expectancy.\n\ndata_qog %>% \n  ggplot()+\n  aes(x = wdi_gdpcapcon2010, y = wdi_lifexp, color = my_region)+\n  geom_point(alpha = 1)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")+\n  scale_color_brewer(palette = \"Set1\")+\n  labs(title = \"Life expectancy and GDP per capital across countries and time\")+\n   xlab(\"GDP per capita\")+\n  ylab(\"Life expectancy\")\n\n\n\n\n\n\n\n\n\nRegion with low GDP per cap and low life expectancy tends to be Sub-Saharan Africa\nRegions with high GDP per cap and high life expectancy tend to be Europe and America\nRegions for which life expectancy tend to be relatively lower than their GDP per cap is North Africa & Middle East and some countries of Sub-Saharan Africa\n\nNorth Africa and Middle East is an interesting case whose observations stand out in the graph above. Around 50000 gdp per cap, life expectancy seems to even decrease with gdp per cap. Thus, I am going to include several variable to see any pattern.\nI reproduce the graph by adding two variables: br_dem and wdi_expmil, my guess is that countries which are democratic and with few military expenditures are expected to have high GDP PC and high life expectancy (for example because less money in invested in the military and more in health care) and conversely. I expect the countries which had a declining trend in the previous graph to have relatively high military expenditure. I also add lines aesthetics to distinguish countries within the regions.\n\ndata_qog %>%  \n  ggplot()+\n  aes(x = wdi_gdpcapcon2010, y = wdi_lifexp, color = my_region, shape = factor(br_dem), size = wdi_expmil)+\n  geom_line(aes(x = wdi_gdpcapcon2010, y = wdi_lifexp, fill = cname, color = my_region), inherit.aes = FALSE)+\n  geom_point(alpha = 0.9)+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")+\n  scale_color_brewer(palette = \"Set1\")+\n  scale_size_continuous(name = \"Military expenditure % of GDP\",\n                        range = c(0, 15))+\n  scale_shape_discrete(name = \"Is country democratic\")+\n  labs(title = \"Life expectancy and GDP per capital across countries and time\")+\n  xlab(\"GDP per capita\")+\n  ylab(\"Life expectancy\")\n\n\n\n\n\n\n\n\nI can see now that European countries tend to have relatively low military expenditure, have a posititve correlation between life expectancy and GDP per capita and tend to be democratic. Sub-Saharan Africa countries tend to have increasing life expectancy over the years, but no important GDP per capita growth. For Asia, There is also a positive correlation between life expectancy and gdp per cap, except for one country. The difference with Europe is that some Asian countries are not democratic (circle = non democratic). North Africa and Middle East is the most intriguing case, with a non democratic country with very high military expenditure and high fluctuation of life expectancy and another non democratic country with negative correlation between life expectancy and GDP per cap.\n\ntypeof(data_qog$br_dem)\n\n[1] \"double\"\n\ntypeof(data_qog$p_polity2)\n\n[1] \"double\"\n\nrange(data_qog$p_polity2, na.rm = TRUE)\n\n[1] -10  10\n\n\nbr_dem (is the country a democracy) is stored as a double, it is however a dummy variable (nominal variable) taking value 0 is country is not democratic and 1 if country is a democracy. Thus, it does not make sense to compute its mean, I should make a table with the frequencies or relative frequencies or do a barplot.\np_polity2 is also stored as a double. It also does not make sense because p_polity2 (revised combined polity score) is an ordinal variable ranging from -10 (strongly autocratic) to +10 (strongly democratic). To give information about this variable, I would do a table and a barplot (sorted according to the range).\nI first transform those two variables into factors\n\ndata_qog$br_dem <- factor(data_qog$br_dem, levels = c(0,1), labels = c(\"Not democratic\", \"democratic\"))\n\ndata_qog$p_polity2 <- factor(data_qog$p_polity2, levels = (-10:10))\n\nI then do some univariate and bivariate analysis of the variables through tables and a cross table\n\ndata_qog %>%\n  count(p_polity2) %>% \n  kable(caption = \"Is the country democratic\", align = \"c\")\n\n\nIs the country democratic\n\n\np_polity2\nn\n\n\n\n\n-10\n287\n\n\n-9\n606\n\n\n-8\n328\n\n\n-7\n1311\n\n\n-6\n419\n\n\n-5\n190\n\n\n-4\n231\n\n\n-3\n240\n\n\n-2\n148\n\n\n-1\n177\n\n\n0\n224\n\n\n1\n114\n\n\n2\n95\n\n\n3\n123\n\n\n4\n252\n\n\n5\n334\n\n\n6\n469\n\n\n7\n386\n\n\n8\n593\n\n\n9\n516\n\n\n10\n1577\n\n\nNA\n3536\n\n\n\n\ndata_qog %>% \n  count(br_dem) %>%\n  kable(caption = \"Is the country democratic\", align = \"c\")\n\n\nIs the country democratic\n\n\nbr_dem\nn\n\n\n\n\nNot democratic\n5140\n\n\ndemocratic\n4915\n\n\nNA\n2101\n\n\n\n\nkable(table(data_qog$p_polity2, data_qog$br_dem), caption = \"Revised combined polity score according to democracy or not\")\n\n\nRevised combined polity score according to democracy or not\n\n\n\nNot democratic\ndemocratic\n\n\n\n\n-10\n287\n0\n\n\n-9\n577\n0\n\n\n-8\n311\n0\n\n\n-7\n1206\n9\n\n\n-6\n406\n5\n\n\n-5\n155\n20\n\n\n-4\n229\n1\n\n\n-3\n209\n26\n\n\n-2\n145\n2\n\n\n-1\n164\n13\n\n\n0\n208\n11\n\n\n1\n91\n23\n\n\n2\n74\n21\n\n\n3\n77\n46\n\n\n4\n127\n125\n\n\n5\n101\n233\n\n\n6\n139\n327\n\n\n7\n41\n339\n\n\n8\n48\n545\n\n\n9\n43\n473\n\n\n10\n8\n1569\n\n\n\n\n\nI choose then to do a mosaic plot of p_polity according to br_dem to represent the association of the two variable visually\n\ndata_qog %>%\n  ggplot()+\n  geom_mosaic(aes(x = product(br_dem, p_polity2), fill = br_dem), na.rm = TRUE)+\n  theme_minimal()+\n  scale_fill_brewer(palette = \"Set1\", name = \"\")+\n  ylab(\"\")+\n  xlab(\"Revised Combined Polity Score: from -10 (strongly authocratic) to 10 (strongly democratic)\")+\n  ggtitle(\"Revised Combined Polity Score and democracy\")\n\n\n\n\n\n\n\n\nI can see that as the Revised Combined Polity Score index on the x axis increases, countries tend to be democratic. The value 4 of Revised Combined Polity Score index seems to be the turning point: before this value, there are more non democratic countries, after the value (4), most of the countries are democratic. However, there still are not democratic countries that have high revised combined polity score, which implies that there is some “disagreement” between the two variable and their definition of what a democracy is (at least for some countries).\nAnother possiblity is to do a stacked or dodge barplot of p_polity and br_dem\n\ndata_qog %>% \n  drop_na() %>% \n  ggplot()+\n  aes(x = p_polity2, y = (..count..)/sum(..count..), fill = br_dem)+\n  geom_bar(position = \"dodge\")+\n  scale_fill_brewer(palette = \"Set1\", name = \"\")+\n  ylab(\"\")+\n  xlab(\"Revised Combined Polity Score from -10 (strongly authocratic) to 10 (strongly democratic)\")+\n  theme_minimal()\n\n\n\n\n\n\n\ndata_qog %>% \n  drop_na() %>% \n  ggplot()+\n  aes(x = p_polity2, y = (..count..)/sum(..count..), fill = br_dem)+\n  geom_bar()+\n  scale_fill_brewer(palette = \"Set1\", name = \"\")+\n  ylab(\"\")+\n  xlab(\"Revised Combined Polity Score from -10 (strongly authocratic) to 10 (strongly democratic)\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\nMy analysis is here the same as the previous graph."
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/how to do maps with r studio.html",
    "href": "posts/Some data analysis and how to do a map with r/how to do maps with r studio.html",
    "title": "How to do maps with R studio",
    "section": "",
    "text": "What follows is a short demonstration on how to do choropleth map in R studio and was part of a bonus task of a practical of one of my master’s courses on applied methods with R. I tried to do some maps and the result was good despite the fact that It can take a long time to figure out how to do. This post is thus for anyone who wants to see how maps can be done on R studio without wasting too much time."
  },
  {
    "objectID": "posts/Some data analysis and how to do a map with r/how to do maps with r studio.html#description-of-some-variables-of-the-dataset",
    "href": "posts/Some data analysis and how to do a map with r/how to do maps with r studio.html#description-of-some-variables-of-the-dataset",
    "title": "How to do maps with R studio",
    "section": "Description of some variables of the dataset",
    "text": "Description of some variables of the dataset\n\n\n\n\n\n\n\n\nVariable name\nShort description\nInformation\n\n\n\n\nccode\nCountry code\nCountry code with the ISO-3166-1 standard\n\n\ncname\nCountry name\nCountry name\n\n\nyear\nYear\n\n\n\nht_region\nRegion of the Country\nTenfold politico-geographic classification of world region from 1 to 10\n\n\nwdi_area\nLand area (sq.km)\nCountry’s total area excluding area under inland water bodies, exclusive economic zones and claims to continental shelf\n\n\nwdi_pop\nTotal population\nAll residents regardless of legal status or citizenship (midyear estimates)\n\n\nwdi_popden\nPopulation density\nPeople per sq. km of land area. Midyear population divided by land area in square kilometers\n\n\nbr_dem\nIs the country a democracy\nDummy variable indicator of democracy based on minimalist definition (if there is free and fair election, peaceful turnover of officers)\n\n\nbr_elect\nTypology of political institutions\nAlternative democracy indicator capturing degree of multi-party competition.\n\n\nchga_hinst\nRegime Institutions\nSix-fold classification of political regimes\n\n\nht_regtype\nRegime Type\nQualitative variable representing the political regime of each country based on 26 levels\n\n\np_polity2\nRevised Combined Polity Score\nOrdinal variable: range from -10 (strongly autocratic) to +10 (strongly democratic)\n\n\nwdi_gnicon2010\nGNI (constant 2010 US dollar)\nGross national income: sum of value added by all resident producers plus any product taxes less subsidies\n\n\nwdi_gnicapcon2010\nGNI per capital (constant 2010 US dollar)\nGNI divided by midyear population\n\n\nwdi_gdpcapcon2010\nGDP per capita (constant 2010 US dollar)\nGross domestic product divided by midyear population. GDP is the sum of gross value added by residents producers plus product taxes minus subsidies\n\n\nwdi_lifexp\nLife expectancy at birth, total (years)\nNumber of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life\n\n\nwdi_litrad\nLiteracy rate, adult total (% of people ages 15 and above)\nPercentage of the population above 15 who can understand, read and write a short simple statement\n\n\nundp_hdi\nHuman Development Index\nSummary measure of average achievement in health, knowledge and decent standards of living\n\n\nwdi_expmil\nMilitary expenditure (% of GDP)\nAll current and capital expenditures on the armed forces\n\n\nwdi_internet\nIndividuals using the Internet (% of population)\nInternet users who have used Internet in the last 3 months"
  },
  {
    "objectID": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html",
    "href": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html",
    "title": "Notes on the methodology of the WPID",
    "section": "",
    "text": "library(tidyverse)\nlibrary(haven)\nsetwd(\"F:/myblog/posts/Techinal notes of political cleavages and inequality\")"
  },
  {
    "objectID": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#how-far-can-we-go-with-income-brackets",
    "href": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#how-far-can-we-go-with-income-brackets",
    "title": "Notes on the methodology of the WPID",
    "section": "How far can we go with income brackets?",
    "text": "How far can we go with income brackets?\nTo build their database on World political cleavages and inequality, Piketty and his team had to use electoral survey data. One problem with these sources is that they collect income data through brackets, without reporting the overall income average of the sample or the average per bracket. This Thus poses the question of how far one can go in terms of statistical analysis with only income brackets as a source of information for income. I will here explore what can be done with such a variable as well as the technical note that Piketty et al. (2021) provides to explain how they computed the vote share for income and education decile, which they claim is one of their main contributions on political cleavages and inequality.\n\nA first look on the WPID dataset\nThe wpid is based on an impressive dataset compiling electoral survey data of 500 elections since 1948. Since the technical note takes Canada’s 2015 election as an example, I will use the latter here.\n\nca <- read_dta(\"ca.dta\")\nca2015 <- ca %>% \n  filter(year == 2015)\nrm(ca)\n\nNote that there is already something weird here: in the dataset, the variable income has 20 brackets/categories here whereas it has 18 in the technical note. Since this is not so much of an issue, I will still work with this dataset and we just won’t have the same results as in Piketty & al’s example.\nA first step in analyzing such a variable is to compute the frequency, relative frequency and the cumulative frequencies. Note that I only take the individuals who vote the the New Democratic Party (NDP) as in the technical note’s example:\n\nca2015 %>% filter(votendp == 1) %>% \n  count(inc) %>% \n  drop_na() %>% \n  ungroup() %>% \n  mutate(\n    cum.n = cumsum(n),\n    prop = n/sum(n),\n    cumrelfreqN = cumsum(prop),\n    cumrelfreqInc = cumsum(inc/sum(inc))) -> table.income\n\ntable.income %>% \n  gt(caption = \"Distribution of income groups\")\n\n\n\n\n\n  Distribution of income groups\n  \n  \n    \n      inc\n      n\n      cum.n\n      prop\n      cumrelfreqN\n      cumrelfreqInc\n    \n  \n  \n    1\n53\n53\n0.07230559\n0.07230559\n0.004975124\n    2\n56\n109\n0.07639836\n0.14870396\n0.014925373\n    3\n15\n124\n0.02046385\n0.16916780\n0.029850746\n    4\n35\n159\n0.04774898\n0.21691678\n0.049751244\n    5\n53\n212\n0.07230559\n0.28922237\n0.074626866\n    6\n47\n259\n0.06412005\n0.35334243\n0.104477612\n    7\n44\n303\n0.06002729\n0.41336971\n0.139303483\n    8\n71\n374\n0.09686221\n0.51023192\n0.179104478\n    10\n34\n408\n0.04638472\n0.55661664\n0.228855721\n    11\n35\n443\n0.04774898\n0.60436562\n0.283582090\n    12\n50\n493\n0.06821282\n0.67257844\n0.343283582\n    13\n28\n521\n0.03819918\n0.71077763\n0.407960199\n    14\n56\n577\n0.07639836\n0.78717599\n0.477611940\n    15\n19\n596\n0.02592087\n0.81309686\n0.552238806\n    16\n26\n622\n0.03547067\n0.84856753\n0.631840796\n    17\n35\n657\n0.04774898\n0.89631651\n0.716417910\n    18\n23\n680\n0.03137790\n0.92769441\n0.805970149\n    19\n32\n712\n0.04365621\n0.97135061\n0.900497512\n    20\n21\n733\n0.02864939\n1.00000000\n1.000000000\n  \n  \n  \n\n\n\n\nWe can then plot income groups against their proportion\n\ntable.income %>% \n  ggplot()+\n  aes(x = factor(inc), y = prop)+\n  geom_col()+\n  theme_bw()+\n  xlab(\"Income group\") -> income.group.plot\n\nincome.group.plot\n\n\n\n\nDistribution of Income groups: Canadian 2015 election survey\n\n\n\n\nIf we plot the income group against the relative cumulative frequency, we obtain the cumulative distribution of income groups. The cumulative distribution can also be directly plotted with plot(ecdf()):\n\ntable.income %>% \n  ggplot()+\n  aes(x = factor(inc), y = cumrelfreqN)+\n  geom_point()+\n  theme_bw()+\n  xlab(\"Income group\")+\n  labs(title = \"Cumulative distribution of Income group: 2015 Canadian election survey\")\n\n\n\n\nIf we plot this relative cumulative distribution of observation against the one for income, we get the Lorenz curve:\n\ntable.income %>% \n  ggplot()+\n  aes(x = cumrelfreqN, y = cumrelfreqInc)+\n  geom_point()+\n  geom_line()+\n  geom_abline(intercept = 0, slope = 1, color = \"blue\")+\n  theme_bw()+\n  labs(\"Lorenz curve\")\n\n\n\n\nWhat makes Piketty’s team approach special and interesting is their systematic analysis in terms of quantile groups. This is, according to them, their main contribution and this approach has the advantage to allow for systematic comparison accross space and time. We will try to reproduce here their conversion of income group into quantiles.\nIn R, the decile for each observation can be added to the dataset with the function ntile():\n\nca2015 <- ca2015 %>% \n  mutate(\n  decile = ntile(inc, 10)\n)\n\nNow, the last column of ca2015 is the decile for each observation in the dataset.\n\nca2015 %>% filter(votendp == 1) %>% \n  group_by(decile) %>% \n  count(votendp) %>% \n  drop_na() %>% \n  ungroup() %>% \n  mutate(prop = n/sum(n),\n         cumsumprop = cumsum(prop)) -> table.income.vote\n\ntable.income.vote %>% gt(caption = \"Proportion of vote for the NDP per income decile\")\n\n\n\n\n\n  Proportion of vote for the NDP per income decile\n  \n  \n    \n      decile\n      votendp\n      n\n      prop\n      cumsumprop\n    \n  \n  \n    1\n1\n76\n0.10368349\n0.1036835\n    2\n1\n70\n0.09549795\n0.1991814\n    3\n1\n106\n0.14461119\n0.3437926\n    4\n1\n81\n0.11050477\n0.4542974\n    5\n1\n57\n0.07776262\n0.5320600\n    6\n1\n88\n0.12005457\n0.6521146\n    7\n1\n70\n0.09549795\n0.7476126\n    8\n1\n67\n0.09140518\n0.8390177\n    9\n1\n63\n0.08594816\n0.9249659\n    10\n1\n55\n0.07503411\n1.0000000\n  \n  \n  \n\n\n\n\n\ntable.income.vote %>% \n  ggplot()+\n  aes(x = factor(decile), y = prop)+\n  geom_col()+\n  theme_bw()+\n  xlab(\"decile\") +\n  ylab(\"\")-> decile.plot\n\ncowplot::plot_grid(income.group.plot, decile.plot)\n\n\n\n\nProportion of NDP voters per income groups (left) and decile (right)\n\n\n\n\nThe figure here tried to reproduce figure 1 of Piketty & al.’s technical note. This not the exact same graph because the income variable in the technical note has 18 brackets whereas it has 20 here. But the result, if the methodology employed here is correct, is pretty much the same.\nFinally, one can also try to fit a “Pareto line” to the income bracket data. Vilfredo Pareto (1848-1923) is well-known for being one of the first economist to have computed inequality indices (his famous alpha coefficient) directly from personal income distribution data. His relationship \\(log(N) = A-\\alpha log(x)\\), with N the number of people earning more than income level x, is a famous relationship and almost every course on income inequality measurement starts with it.\nFirst, a table need to be constructed from the data, we count the number of observation per income bracket and compute the inverse of the cumulative relative frequencies, which is the same as N is Pareto’s equation.\n\nca2015 %>% \n  count(inc) %>% \n  mutate(prop = n/sum(n),\n         cumrelfreq = cumsum(prop),\n         inverse_rcdf = rev(cumrelfreq)) -> paretotable\n\nparetotable %>% \n  gt()\n\n\n\n\n\n  \n  \n    \n      inc\n      n\n      prop\n      cumrelfreq\n      inverse_rcdf\n    \n  \n  \n    1\n211\n0.04687847\n0.04687847\n1.00000000\n    2\n327\n0.07265052\n0.11952899\n0.87136192\n    3\n79\n0.01755166\n0.13708065\n0.82914908\n    4\n210\n0.04665630\n0.18373695\n0.78626972\n    5\n199\n0.04421240\n0.22794934\n0.75960898\n    6\n184\n0.04087980\n0.26882915\n0.70451011\n    7\n188\n0.04176850\n0.31059764\n0.66985114\n    8\n421\n0.09353477\n0.40413242\n0.64185737\n    10\n205\n0.04554543\n0.44967785\n0.57209509\n    11\n166\n0.03688069\n0.48655854\n0.53921351\n    12\n237\n0.05265497\n0.53921351\n0.48655854\n    13\n148\n0.03288158\n0.57209509\n0.44967785\n    14\n314\n0.06976228\n0.64185737\n0.40413242\n    15\n126\n0.02799378\n0.66985114\n0.31059764\n    16\n156\n0.03465896\n0.70451011\n0.26882915\n    17\n248\n0.05509887\n0.75960898\n0.22794934\n    18\n120\n0.02666074\n0.78626972\n0.18373695\n    19\n193\n0.04287936\n0.82914908\n0.13708065\n    20\n190\n0.04221284\n0.87136192\n0.11952899\n    NA\n579\n0.12863808\n1.00000000\n0.04687847\n  \n  \n  \n\n\n\n\nFinally, one can plot the log of the inverse of the relative cumulative distribution function against the log of the income groups:\n\nparetotable %>% \n  ggplot()+\n  aes(x = log(inc), y = log(rev(cumrelfreq)))+\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  theme_bw()\n\n\n\n\nWe can see that the line does not fit the data very well. As explained by Milanovic, the Pareto line fits well only for the top of income distribution. In fact, the data on personal income distribution that Pareto had only collected income data of the very rich. If he had data covering more than the top 1 percent, he would have probably made similar graphs as here and as in Milanovic’s blog post."
  },
  {
    "objectID": "Techinal notes of political cleavages and inequality/technical note piketty 2021.html#how-far-can-we-go-with-income-brackets",
    "href": "Techinal notes of political cleavages and inequality/technical note piketty 2021.html#how-far-can-we-go-with-income-brackets",
    "title": "Notes on the methodology of the WPID",
    "section": "How far can we go with income brackets?",
    "text": "How far can we go with income brackets?\nTo build their database on World political cleavages and inequality, Piketty and his team had to use electoral survey data. One problem with these sources is that they collect income data through brackets, without reporting the overall income average of the sample or the average per bracket. This Thus poses the question of how far one can go in terms of statistical analysis with only income brackets as a source of information for income. I will here explore what can be done with such a variable as well as the technical note that Piketty et al. (2021) provides to explain how they computed the vote share for income and education decile, which they claim is one of their main contributions on political cleavages and inequality.\n\nA first look on the WPID dataset\nThe wpid is based on an impressive dataset compiling electoral survey data of 500 elections since 1948. Since the technical note takes Canada’s 2015 election as an example, I will use the latter here.\n\nca <- read_dta(\"ca.dta\")\nca2015 <- ca %>% \n  filter(year == 2015)\nrm(ca)\n\nNote that there is already something weird here: in the dataset, the variable income has 20 brackets/categories here whereas it has 18 in the technical note. Since this is not so much of an issue, I will still work with this dataset and we just won’t have the same results as in Piketty & al’s example.\nA first step in analyzing such a variable is to compute the frequency, relative frequency and the cumulative frequencies. Note that I only take the individuals who vote the the New Democratic Party (NDP) as in the technical note’s example:\n\nca2015 %>% filter(votendp == 1) %>% \n  count(inc) %>% \n  drop_na() %>% \n  ungroup() %>% \n  mutate(\n    cum.n = cumsum(n),\n    prop = n/sum(n),\n    cumrelfreqN = cumsum(prop),\n    cumrelfreqInc = cumsum(inc/sum(inc))) -> table.income\n\ntable.income %>% \n  gt(caption = \"Distribution of income groups\")\n\n\n\n\n\n  Distribution of income groups\n  \n  \n    \n      inc\n      n\n      cum.n\n      prop\n      cumrelfreqN\n      cumrelfreqInc\n    \n  \n  \n    1\n53\n53\n0.07230559\n0.07230559\n0.004975124\n    2\n56\n109\n0.07639836\n0.14870396\n0.014925373\n    3\n15\n124\n0.02046385\n0.16916780\n0.029850746\n    4\n35\n159\n0.04774898\n0.21691678\n0.049751244\n    5\n53\n212\n0.07230559\n0.28922237\n0.074626866\n    6\n47\n259\n0.06412005\n0.35334243\n0.104477612\n    7\n44\n303\n0.06002729\n0.41336971\n0.139303483\n    8\n71\n374\n0.09686221\n0.51023192\n0.179104478\n    10\n34\n408\n0.04638472\n0.55661664\n0.228855721\n    11\n35\n443\n0.04774898\n0.60436562\n0.283582090\n    12\n50\n493\n0.06821282\n0.67257844\n0.343283582\n    13\n28\n521\n0.03819918\n0.71077763\n0.407960199\n    14\n56\n577\n0.07639836\n0.78717599\n0.477611940\n    15\n19\n596\n0.02592087\n0.81309686\n0.552238806\n    16\n26\n622\n0.03547067\n0.84856753\n0.631840796\n    17\n35\n657\n0.04774898\n0.89631651\n0.716417910\n    18\n23\n680\n0.03137790\n0.92769441\n0.805970149\n    19\n32\n712\n0.04365621\n0.97135061\n0.900497512\n    20\n21\n733\n0.02864939\n1.00000000\n1.000000000\n  \n  \n  \n\n\n\n\nWe can then plot income groups against their proportion\n\ntable.income %>% \n  ggplot()+\n  aes(x = factor(inc), y = prop)+\n  geom_col()+\n  theme_bw()+\n  xlab(\"Income group\") -> income.group.plot\n\nincome.group.plot\n\n\n\n\nDistribution of Income groups: Canadian 2015 election survey\n\n\n\n\nIf we plot the income group against the relative cumulative frequency, we obtain the cumulative distribution of income groups. The cumulative distribution can also be directly plotted with plot(ecdf()):\n\ntable.income %>% \n  ggplot()+\n  aes(x = factor(inc), y = cumrelfreqN)+\n  geom_point()+\n  theme_bw()+\n  xlab(\"Income group\")+\n  labs(title = \"Cumulative distribution of Income group: 2015 Canadian election survey\")\n\n\n\n\nIf we plot this relative cumulative distribution of observation against the one for income, we get the Lorenz curve:\n\ntable.income %>% \n  ggplot()+\n  aes(x = cumrelfreqN, y = cumrelfreqInc)+\n  geom_point()+\n  geom_line()+\n  geom_abline(intercept = 0, slope = 1, color = \"blue\")+\n  theme_bw()+\n  labs(\"Lorenz curve\")\n\n\n\n\nWhat makes Piketty’s team approach special and interesting is their systematic analysis in terms of quantile groups. This is, according to them, their main contribution and this approach has the advantage to allow for systematic comparison accross space and time. We will try to reproduce here their conversion of income group into quantiles.\nIn R, the decile for each observation can be added to the dataset with the function ntile():\n\nca2015 <- ca2015 %>% \n  mutate(\n  decile = ntile(inc, 10)\n)\n\nNow, the last column of ca2015 is the decile for each observation in the dataset.\n\nca2015 %>% filter(votendp == 1) %>% \n  group_by(decile) %>% \n  count(votendp) %>% \n  drop_na() %>% \n  ungroup() %>% \n  mutate(prop = n/sum(n),\n         cumsumprop = cumsum(prop)) -> table.income.vote\n\ntable.income.vote %>% gt(caption = \"Proportion of vote for the NDP per income decile\")\n\n\n\n\n\n  Proportion of vote for the NDP per income decile\n  \n  \n    \n      decile\n      votendp\n      n\n      prop\n      cumsumprop\n    \n  \n  \n    1\n1\n76\n0.10368349\n0.1036835\n    2\n1\n70\n0.09549795\n0.1991814\n    3\n1\n106\n0.14461119\n0.3437926\n    4\n1\n81\n0.11050477\n0.4542974\n    5\n1\n57\n0.07776262\n0.5320600\n    6\n1\n88\n0.12005457\n0.6521146\n    7\n1\n70\n0.09549795\n0.7476126\n    8\n1\n67\n0.09140518\n0.8390177\n    9\n1\n63\n0.08594816\n0.9249659\n    10\n1\n55\n0.07503411\n1.0000000\n  \n  \n  \n\n\n\n\n\ntable.income.vote %>% \n  ggplot()+\n  aes(x = factor(decile), y = prop)+\n  geom_col()+\n  theme_bw()+\n  xlab(\"decile\") +\n  ylab(\"\")-> decile.plot\n\ncowplot::plot_grid(income.group.plot, decile.plot)\n\n\n\n\nProportion of NDP voters per income groups (left) and decile (right)\n\n\n\n\n\nca2015 %>% \n  count(inc) %>% \n  mutate(prop = n/sum(n),\n         cumrelfreq = cumsum(prop),\n         inverse_cdf = rev(cumrelfreq)) -> paretotable\n\nparetotable %>% \n  gt()\n\n\n\n\n\n  \n  \n    \n      inc\n      n\n      prop\n      cumrelfreq\n      inverse_cdf\n    \n  \n  \n    1\n211\n0.04687847\n0.04687847\n1.00000000\n    2\n327\n0.07265052\n0.11952899\n0.87136192\n    3\n79\n0.01755166\n0.13708065\n0.82914908\n    4\n210\n0.04665630\n0.18373695\n0.78626972\n    5\n199\n0.04421240\n0.22794934\n0.75960898\n    6\n184\n0.04087980\n0.26882915\n0.70451011\n    7\n188\n0.04176850\n0.31059764\n0.66985114\n    8\n421\n0.09353477\n0.40413242\n0.64185737\n    10\n205\n0.04554543\n0.44967785\n0.57209509\n    11\n166\n0.03688069\n0.48655854\n0.53921351\n    12\n237\n0.05265497\n0.53921351\n0.48655854\n    13\n148\n0.03288158\n0.57209509\n0.44967785\n    14\n314\n0.06976228\n0.64185737\n0.40413242\n    15\n126\n0.02799378\n0.66985114\n0.31059764\n    16\n156\n0.03465896\n0.70451011\n0.26882915\n    17\n248\n0.05509887\n0.75960898\n0.22794934\n    18\n120\n0.02666074\n0.78626972\n0.18373695\n    19\n193\n0.04287936\n0.82914908\n0.13708065\n    20\n190\n0.04221284\n0.87136192\n0.11952899\n    NA\n579\n0.12863808\n1.00000000\n0.04687847\n  \n  \n  \n\n\n\n\n\nparetotable %>% \n  ggplot()+\n  aes(x = log(inc), y = log(rev(cumrelfreq)))+\n  geom_point()+\n  geom_line()+\n  geom_smooth(method = \"lm\")+\n  theme_bw()"
  },
  {
    "objectID": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#how-far-can-we-go-with-income-brackets-in-progress",
    "href": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#how-far-can-we-go-with-income-brackets-in-progress",
    "title": "From income brackets to income decile",
    "section": "How far can we go with income brackets? (in progress)",
    "text": "How far can we go with income brackets? (in progress)\nTo build their database on World political cleavages and inequality, Piketty and his team had to use electoral survey data. One problem with these sources is that they collect income data through brackets, without reporting the overall income average of the sample or the average per bracket. This Thus poses the question of how far one can go in terms of statistical analysis with only income brackets as a source of information for income. I will here explore what can be done with such a variable as well as the technical note that Piketty et al. (2021) provides to explain how they computed the vote share for income and education decile, which they claim is one of their main contributions on political cleavages and inequality.\n\nFrom brackets to decile\nThe wpid is based on an impressive dataset compiling electoral survey data of 500 elections since 1948. Since the technical note takes Canada’s 2015 election as an example, I will use the latter here.\n\nrm(list = ls())\nca <- read_dta(\"ca.dta\")\nca2015 <- ca %>% \n  filter(year == 2015)\nrm(ca)\n\nsort(unique(ca2015$inc))\n\n [1]  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20\n\n\nNote that there is already something going on here: in the dataset, the variable income has 19 brackets/categories here whereas it has 18 in the technical note. Furthermore, income brackets “jump” from 8 to 10. I will ignore these issues and still work with this dataset, we just won’t have the same results as in Piketty & al’s example.\nA first step in analyzing such a variable is to compute the frequency, relative frequency and the cumulative frequencies. More precisely, I will construct two tables. On the one hand, I compute the descriptive statistics for the NDP’s voters within each income brackets. On the other hand, I construct a table for the overall distribution of income brackets for the NPD’s voters only. Note that I directly add the proportion of NDP’s voters from the first table to the second one to simplify further calculations:\n\nca2015 %>%\n  group_by(inc) %>% \n  count(votendp) %>% \n  drop_na() %>% \n  mutate(\n    cum.n = cumsum(n),\n    prop = n/sum(n)) %>% ungroup() -> table.income.pervote\n\nca2015 %>% filter(votendp == 1) %>% \n  group_by(inc) %>% \n  count(votendp) %>% \n  drop_na() %>% \n  ungroup() %>% \n  mutate(\n    prop_vote = table.income.pervote$prop[table.income.pervote$votendp == 1],\n    cum.n = cumsum(n),\n    prop = n/sum(n),\n    rangeleft = lag(cumsum(prop), default = 0),\n    cumrelfreqN = cumsum(prop),\n    cumrelfreqInc = cumsum(inc/sum(inc))) -> table.income\n\ntable.income.pervote %>% \n  gt(caption = \"Distribution of the vote for the NDP by income group\")\n\n\n\n\n\n  Distribution of the vote for the NDP by income group\n  \n  \n    \n      inc\n      votendp\n      n\n      cum.n\n      prop\n    \n  \n  \n    1\n0\n114\n114\n0.6826347\n    1\n1\n53\n167\n0.3173653\n    2\n0\n161\n161\n0.7419355\n    2\n1\n56\n217\n0.2580645\n    3\n0\n49\n49\n0.7656250\n    3\n1\n15\n64\n0.2343750\n    4\n0\n129\n129\n0.7865854\n    4\n1\n35\n164\n0.2134146\n    5\n0\n108\n108\n0.6708075\n    5\n1\n53\n161\n0.3291925\n    6\n0\n112\n112\n0.7044025\n    6\n1\n47\n159\n0.2955975\n    7\n0\n114\n114\n0.7215190\n    7\n1\n44\n158\n0.2784810\n    8\n0\n244\n244\n0.7746032\n    8\n1\n71\n315\n0.2253968\n    10\n0\n140\n140\n0.8045977\n    10\n1\n34\n174\n0.1954023\n    11\n0\n114\n114\n0.7651007\n    11\n1\n35\n149\n0.2348993\n    12\n0\n154\n154\n0.7549020\n    12\n1\n50\n204\n0.2450980\n    13\n0\n105\n105\n0.7894737\n    13\n1\n28\n133\n0.2105263\n    14\n0\n208\n208\n0.7878788\n    14\n1\n56\n264\n0.2121212\n    15\n0\n95\n95\n0.8333333\n    15\n1\n19\n114\n0.1666667\n    16\n0\n113\n113\n0.8129496\n    16\n1\n26\n139\n0.1870504\n    17\n0\n171\n171\n0.8300971\n    17\n1\n35\n206\n0.1699029\n    18\n0\n83\n83\n0.7830189\n    18\n1\n23\n106\n0.2169811\n    19\n0\n143\n143\n0.8171429\n    19\n1\n32\n175\n0.1828571\n    20\n0\n145\n145\n0.8734940\n    20\n1\n21\n166\n0.1265060\n  \n  \n  \n\n\n\ntable.income %>% \n  gt(caption =  \"Distribution of income group among NDP's voters\")\n\n\n\n\n\n  Distribution of income group among NDP's voters\n  \n  \n    \n      inc\n      votendp\n      n\n      prop_vote\n      cum.n\n      prop\n      rangeleft\n      cumrelfreqN\n      cumrelfreqInc\n    \n  \n  \n    1\n1\n53\n0.3173653\n53\n0.07230559\n0.00000000\n0.07230559\n0.004975124\n    2\n1\n56\n0.2580645\n109\n0.07639836\n0.07230559\n0.14870396\n0.014925373\n    3\n1\n15\n0.2343750\n124\n0.02046385\n0.14870396\n0.16916780\n0.029850746\n    4\n1\n35\n0.2134146\n159\n0.04774898\n0.16916780\n0.21691678\n0.049751244\n    5\n1\n53\n0.3291925\n212\n0.07230559\n0.21691678\n0.28922237\n0.074626866\n    6\n1\n47\n0.2955975\n259\n0.06412005\n0.28922237\n0.35334243\n0.104477612\n    7\n1\n44\n0.2784810\n303\n0.06002729\n0.35334243\n0.41336971\n0.139303483\n    8\n1\n71\n0.2253968\n374\n0.09686221\n0.41336971\n0.51023192\n0.179104478\n    10\n1\n34\n0.1954023\n408\n0.04638472\n0.51023192\n0.55661664\n0.228855721\n    11\n1\n35\n0.2348993\n443\n0.04774898\n0.55661664\n0.60436562\n0.283582090\n    12\n1\n50\n0.2450980\n493\n0.06821282\n0.60436562\n0.67257844\n0.343283582\n    13\n1\n28\n0.2105263\n521\n0.03819918\n0.67257844\n0.71077763\n0.407960199\n    14\n1\n56\n0.2121212\n577\n0.07639836\n0.71077763\n0.78717599\n0.477611940\n    15\n1\n19\n0.1666667\n596\n0.02592087\n0.78717599\n0.81309686\n0.552238806\n    16\n1\n26\n0.1870504\n622\n0.03547067\n0.81309686\n0.84856753\n0.631840796\n    17\n1\n35\n0.1699029\n657\n0.04774898\n0.84856753\n0.89631651\n0.716417910\n    18\n1\n23\n0.2169811\n680\n0.03137790\n0.89631651\n0.92769441\n0.805970149\n    19\n1\n32\n0.1828571\n712\n0.04365621\n0.92769441\n0.97135061\n0.900497512\n    20\n1\n21\n0.1265060\n733\n0.02864939\n0.97135061\n1.00000000\n1.000000000\n  \n  \n  \n\n\n\n\nWe can then plot income groups against their proportion\n\ntable.income.pervote %>% filter(votendp == 1) %>% \n  ggplot()+\n  aes(x = factor(inc), y = prop)+\n  geom_col()+\n  theme_bw()+\n  xlab(\"Income group\") -> income.group.plot\n\ntable.income %>% \n  ggplot()+\n  aes(x = factor(inc), y = prop) %>% \n  geom_col()+\n  theme_bw()+\n  ylab(\"\")+\n  xlab(\"\") -> income.group.plot2\n  \n\ncowplot::plot_grid(income.group.plot, income.group.plot2)\n\n\n\n\nDistribution of Income groups: Canadian 2015 election survey\n\n\n\n\nOn the left, we have a graph very similar to the one of the technical note. The right-sided graph is different, because the proportion are for the overall NPD’s voters whereas the left-sided graph represents the proportion within the income group. For example, 30% of income bracket 1 voted for the NDP, but they represent about 7.4% of total NDP’s voters.\nWhat makes Piketty’s team approach special and interesting is their systematic analysis in terms of quantile groups. This is, according to them, their main contribution and this approach has the advantage to allow for systematic comparison accross space and time. We will try to reproduce here their conversion of income group into quantiles.\nIn R, the decile for each observation can be added to the dataset with the function ntile():\n\nca2015 <- ca2015 %>% \n  mutate(\n  decile = ntile(inc, 10)\n)\n\nNow, the last column of ca2015 is the decile for each observation in the dataset.\n\nca2015 %>% \n  group_by(decile) %>% \n  count(votendp) %>% \n  filter(votendp == 1) %>% \n  drop_na() %>% \n  ungroup() %>% \n  mutate(prop = n/sum(n)) -> table.income.vote\n\ntable.income.vote %>% gt(caption = \"Decile and income bracket\")\n\n\n\n\n\n  Decile and income bracket\n  \n  \n    \n      decile\n      votendp\n      n\n      prop\n    \n  \n  \n    1\n1\n76\n0.10368349\n    2\n1\n70\n0.09549795\n    3\n1\n106\n0.14461119\n    4\n1\n81\n0.11050477\n    5\n1\n57\n0.07776262\n    6\n1\n88\n0.12005457\n    7\n1\n70\n0.09549795\n    8\n1\n67\n0.09140518\n    9\n1\n63\n0.08594816\n    10\n1\n55\n0.07503411\n  \n  \n  \n\n\n\n\nHowever, it is straightforward to see that the ntile() function has flaws in decile computing. More generally, computing income decile when the income variable is in brackets seems complicated, but the technical note proposes a re-weighting average approach to partially solve this problem.\nTo see how the re-weighing approach works, let’s go back to the first table:\n\ntable.income %>%\n  gt()\n\n\n\n\n\n  \n  \n    \n      inc\n      votendp\n      n\n      prop_vote\n      cum.n\n      prop\n      rangeleft\n      cumrelfreqN\n      cumrelfreqInc\n    \n  \n  \n    1\n1\n53\n0.3173653\n53\n0.07230559\n0.00000000\n0.07230559\n0.004975124\n    2\n1\n56\n0.2580645\n109\n0.07639836\n0.07230559\n0.14870396\n0.014925373\n    3\n1\n15\n0.2343750\n124\n0.02046385\n0.14870396\n0.16916780\n0.029850746\n    4\n1\n35\n0.2134146\n159\n0.04774898\n0.16916780\n0.21691678\n0.049751244\n    5\n1\n53\n0.3291925\n212\n0.07230559\n0.21691678\n0.28922237\n0.074626866\n    6\n1\n47\n0.2955975\n259\n0.06412005\n0.28922237\n0.35334243\n0.104477612\n    7\n1\n44\n0.2784810\n303\n0.06002729\n0.35334243\n0.41336971\n0.139303483\n    8\n1\n71\n0.2253968\n374\n0.09686221\n0.41336971\n0.51023192\n0.179104478\n    10\n1\n34\n0.1954023\n408\n0.04638472\n0.51023192\n0.55661664\n0.228855721\n    11\n1\n35\n0.2348993\n443\n0.04774898\n0.55661664\n0.60436562\n0.283582090\n    12\n1\n50\n0.2450980\n493\n0.06821282\n0.60436562\n0.67257844\n0.343283582\n    13\n1\n28\n0.2105263\n521\n0.03819918\n0.67257844\n0.71077763\n0.407960199\n    14\n1\n56\n0.2121212\n577\n0.07639836\n0.71077763\n0.78717599\n0.477611940\n    15\n1\n19\n0.1666667\n596\n0.02592087\n0.78717599\n0.81309686\n0.552238806\n    16\n1\n26\n0.1870504\n622\n0.03547067\n0.81309686\n0.84856753\n0.631840796\n    17\n1\n35\n0.1699029\n657\n0.04774898\n0.84856753\n0.89631651\n0.716417910\n    18\n1\n23\n0.2169811\n680\n0.03137790\n0.89631651\n0.92769441\n0.805970149\n    19\n1\n32\n0.1828571\n712\n0.04365621\n0.92769441\n0.97135061\n0.900497512\n    20\n1\n21\n0.1265060\n733\n0.02864939\n0.97135061\n1.00000000\n1.000000000\n  \n  \n  \n\n\n\n\nWe can directly see the problem posed by income brackets: for example, we can observe that all of income bracket one belongs to the first decile since its relative range is between 0 and 0.0723. However, the relative range of bracket two is [0.0723 - 0.1487]. Some part of it belong to the first decile ([0 - 0.1]), but some belong to the second ([0 - 0.2]). The approach to compute the proportion of observations belonging to the any given decile is to compute the share of each income bracket belonging to this decile and then compute a weighted average. For example, if I want to compute the share of observation of the first decile (D10), I already know that 100% of income bracket one belongs to D10 but I need to know the share of bracket 2 (B2) belonging to D10.\nTo estimate this, let’s assume the distribution of B2 is uniform \\(x \\sim U[0.0723; 0.1487]\\), with x the observation within this range. We want to know \\(P(x<0.1)\\), that is to say, the probability that x belongs to the first decile. We use the uniform cumulative distribution function with parameters min = 0.073 and max = 0.1487: \\(P(x<0.1) = \\frac{0.1-0.0723}{0.1487-0.0723} = 0.3626\\). This means that 36.26% of B2 belongs to D10. Then, the weighted average for the proportion of observation within D10: \\(\\frac{1*0.317+0.3626*0.26}{1+0.3626} = 0.3018\\). 30.2% the first decile voters voted for the NDP in 2015.\nHere are the computations in R:\n\npunif(0.1, table.income$cumrelfreqN[1], table.income$cumrelfreqN[2])\n\n[1] 0.3625\n\n(1*0.317+0.3626*0.26)/(1+0.3626)\n\n[1] 0.3018318\n\nweighted.mean(x = c(table.income$prop_vote[1], table.income$prop_vote[2]), w = c(1, punif(0.1, table.income$cumrelfreqN[1], table.income$cumrelfreqN[2])))\n\n[1] 0.301588\n\n\nUnfortunately, there is to my knowledge no function in R that will compute the weights automatically. I can nonetheless compute them through a tedious for loop:\n\nweight <- rep(NA, length(table.income$inc))\n\nfor (i in 1:length(table.income$inc)) {\n  weight[i] <- ifelse(table.income$cumrelfreqN[i] < 0.1 | table.income$cumrelfreqN[i] == 1, 1,\n                  ifelse(table.income$cumrelfreqN[i] > 0.1 & table.income$cumrelfreqN[i] < 0.2, punif(0.1, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]),\n                         ifelse(table.income$cumrelfreqN[i] > 0.2 & table.income$cumrelfreqN[i] < 0.3, punif(0.2, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]),\n                                ifelse(table.income$cumrelfreqN[i] > 0.3 & table.income$cumrelfreqN[i] < 0.4, punif(0.3, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]),\n                                       ifelse(table.income$cumrelfreqN[i] > 0.4 & table.income$cumrelfreqN[i] < 0.5, punif(0.4, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]), \n                                              ifelse(table.income$cumrelfreqN[i] > 0.5 & table.income$cumrelfreqN[i] < 0.6, punif(0.5, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]), \n                                                     ifelse(table.income$cumrelfreqN[i] > 0.6 & table.income$cumrelfreqN[i] < 0.7, punif(0.6, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]),\n                                                            ifelse(table.income$cumrelfreqN[i] > 0.7 & table.income$cumrelfreqN[i] < 0.8, punif(0.7, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]),\n                                                                   ifelse(table.income$cumrelfreqN[i] > 0.8 & table.income$cumrelfreqN[i] < 0.9, punif(0.8, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]), \n                                                                          ifelse(table.income$cumrelfreqN[i] > 0.9 & table.income$cumrelfreqN[i] < 1, punif(0.9, min = table.income$cumrelfreqN[i-1], max = table.income$cumrelfreqN[i]), 1))))))))))\n}\nweight\n\n [1] 1.0000000 0.3625000 0.0000000 0.6457143 0.0000000 0.1680851 0.7772727\n [8] 0.8943662 0.0000000 0.9085714 0.0000000 0.7178571 0.0000000 0.4947368\n[15] 0.0000000 0.0000000 0.1173913 0.0000000 1.0000000\n\n\nI replace the 0 with 1:\n\nweight <- ifelse(weight == 0, 1, weight)\n\ntable.income <- table.income %>% \n  mutate(share_decile = weight)\n\ntable.income %>% \n  mutate(share_rest = 1 - weight) -> table.income\n\ntable.income %>% mutate(\n  prop_vote = table.income.pervote$prop[table.income.pervote$votendp == 1]\n) %>% gt()\n\n\n\n\n\n  \n  \n    \n      inc\n      votendp\n      n\n      prop_vote\n      cum.n\n      prop\n      rangeleft\n      cumrelfreqN\n      cumrelfreqInc\n      share_decile\n      share_rest\n    \n  \n  \n    1\n1\n53\n0.3173653\n53\n0.07230559\n0.00000000\n0.07230559\n0.004975124\n1.0000000\n0.00000000\n    2\n1\n56\n0.2580645\n109\n0.07639836\n0.07230559\n0.14870396\n0.014925373\n0.3625000\n0.63750000\n    3\n1\n15\n0.2343750\n124\n0.02046385\n0.14870396\n0.16916780\n0.029850746\n1.0000000\n0.00000000\n    4\n1\n35\n0.2134146\n159\n0.04774898\n0.16916780\n0.21691678\n0.049751244\n0.6457143\n0.35428571\n    5\n1\n53\n0.3291925\n212\n0.07230559\n0.21691678\n0.28922237\n0.074626866\n1.0000000\n0.00000000\n    6\n1\n47\n0.2955975\n259\n0.06412005\n0.28922237\n0.35334243\n0.104477612\n0.1680851\n0.83191489\n    7\n1\n44\n0.2784810\n303\n0.06002729\n0.35334243\n0.41336971\n0.139303483\n0.7772727\n0.22272727\n    8\n1\n71\n0.2253968\n374\n0.09686221\n0.41336971\n0.51023192\n0.179104478\n0.8943662\n0.10563380\n    10\n1\n34\n0.1954023\n408\n0.04638472\n0.51023192\n0.55661664\n0.228855721\n1.0000000\n0.00000000\n    11\n1\n35\n0.2348993\n443\n0.04774898\n0.55661664\n0.60436562\n0.283582090\n0.9085714\n0.09142857\n    12\n1\n50\n0.2450980\n493\n0.06821282\n0.60436562\n0.67257844\n0.343283582\n1.0000000\n0.00000000\n    13\n1\n28\n0.2105263\n521\n0.03819918\n0.67257844\n0.71077763\n0.407960199\n0.7178571\n0.28214286\n    14\n1\n56\n0.2121212\n577\n0.07639836\n0.71077763\n0.78717599\n0.477611940\n1.0000000\n0.00000000\n    15\n1\n19\n0.1666667\n596\n0.02592087\n0.78717599\n0.81309686\n0.552238806\n0.4947368\n0.50526316\n    16\n1\n26\n0.1870504\n622\n0.03547067\n0.81309686\n0.84856753\n0.631840796\n1.0000000\n0.00000000\n    17\n1\n35\n0.1699029\n657\n0.04774898\n0.84856753\n0.89631651\n0.716417910\n1.0000000\n0.00000000\n    18\n1\n23\n0.2169811\n680\n0.03137790\n0.89631651\n0.92769441\n0.805970149\n0.1173913\n0.88260870\n    19\n1\n32\n0.1828571\n712\n0.04365621\n0.92769441\n0.97135061\n0.900497512\n1.0000000\n0.00000000\n    20\n1\n21\n0.1265060\n733\n0.02864939\n0.97135061\n1.00000000\n1.000000000\n1.0000000\n0.00000000\n  \n  \n  \n\n\n\n\nThere can be mistakes, but the results seem to make sense\nSince I do not want to ever do this computation again (😅), I put all of this into a function:\n\nweight_share <- function(x){\n  weight <- rep(NA, length(x))\n  \n  for (i in 1:length(x)) {\n   weight[i] <-  ifelse(x[i] < 0.1 | x[i] == 1, 1,\n                  ifelse(x[i] > 0.1 & x[i] < 0.2, punif(0.1, min = x[i-1], max = x[i]),\n                         ifelse(x[i] > 0.2 & x[i] < 0.3, punif(0.2, min = x[i-1], max = x[i]),\n                                ifelse(x[i] > 0.3 & x[i] < 0.4, punif(0.3, min = x[i-1], max = x[i]),\n                                       ifelse(x[i] > 0.4 & x[i] < 0.5, punif(0.4, min = x[i-1], max = x[i]), \n                                              ifelse(x[i] > 0.5 & x[i] < 0.6, punif(0.5, min = x[i-1], max = x[i]), \n                                                     ifelse(x[i] > 0.6 & x[i] < 0.7, punif(0.6, min = x[i-1], max = x[i]),\n                                                            ifelse(x[i] > 0.7 & x[i] < 0.8, punif(0.7, min = x[i-1], max = x[i]),\n                                                                   ifelse(x[i] > 0.8 & x[i] < 0.9, punif(0.8, min = x[i-1], max = x[i]),\n                                                                                                         ifelse(x[i] > 0.9 & x[i] < 1, punif(0.9, min = x[i-1], max = x[i]), 1))))))))))\n  }\n  weight <- ifelse(weight == 0, 1, weight)\n  print(weight)\n}\n\nLet’s check if the function works\n\nweight_share(x = table.income$cumrelfreqN)\n\n [1] 1.0000000 0.3625000 1.0000000 0.6457143 1.0000000 0.1680851 0.7772727\n [8] 0.8943662 1.0000000 0.9085714 1.0000000 0.7178571 1.0000000 0.4947368\n[15] 1.0000000 1.0000000 0.1173913 1.0000000 1.0000000\n\n\nWe are almost done, there are only the weighted averages for each decile left to calculate. One further step is to compute dummy variables to show to which decile income brackets belong to. This will produce a table close to the one from the technical note.\n\ntable.income %>% \n  mutate(d1 = ifelse(table.income$rangeleft >= 0 & table.income$rangeleft < 0.1, 1, 0),\n         d2 = ifelse(table.income$rangeleft %[]% c(0.1, 0.2) | table.income$cumrelfreqN %[]% c(0.1, 0.2), 1, 0),  # the %[]% is an within bracket operator from the Desctools package. for example, x %[]% c(a, b) checks whether x belong to the interval [a, b] with a<b \n         d3 = ifelse(table.income$rangeleft %[]% c(0.2, 0.3) | table.income$cumrelfreqN %[]% c(0.2, 0.3), 1, 0),\n         d4 = ifelse(table.income$rangeleft %[]% c(0.3, 0.4) | table.income$cumrelfreqN %[]% c(0.3, 0.4), 1, 0),\n         d5 = ifelse(table.income$rangeleft %[]% c(0.4, 0.5) | table.income$cumrelfreqN %[]% c(0.4, 0.5), 1, 0),\n         d6 = ifelse(table.income$rangeleft %[]% c(0.5, 0.6) | table.income$cumrelfreqN %[]% c(0.5, 0.6), 1, 0),\n         d7 = ifelse(table.income$rangeleft %[]% c(0.6, 0.7) | table.income$cumrelfreqN %[]% c(0.6, 0.7), 1, 0),\n         d8 = ifelse(table.income$rangeleft %[]% c(0.7, 0.8) | table.income$cumrelfreqN %[]% c(0.7, 0.8), 1, 0),\n         d9 = ifelse(table.income$rangeleft %[]% c(0.8, 0.9) | table.income$cumrelfreqN %[]% c(0.8, 0.9), 1, 0),\n         d10 = ifelse(table.income$rangeleft %[]% c(0.9, 1) | table.income$cumrelfreqN %[]% c(0.9, 1), 1, 0)) -> table.income\n\ntable.income %>% gt()\n\n\n\n\n\n  \n  \n    \n      inc\n      votendp\n      n\n      prop_vote\n      cum.n\n      prop\n      rangeleft\n      cumrelfreqN\n      cumrelfreqInc\n      share_decile\n      share_rest\n      d1\n      d2\n      d3\n      d4\n      d5\n      d6\n      d7\n      d8\n      d9\n      d10\n    \n  \n  \n    1\n1\n53\n0.3173653\n53\n0.07230559\n0.00000000\n0.07230559\n0.004975124\n1.0000000\n0.00000000\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n    2\n1\n56\n0.2580645\n109\n0.07639836\n0.07230559\n0.14870396\n0.014925373\n0.3625000\n0.63750000\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n    3\n1\n15\n0.2343750\n124\n0.02046385\n0.14870396\n0.16916780\n0.029850746\n1.0000000\n0.00000000\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n    4\n1\n35\n0.2134146\n159\n0.04774898\n0.16916780\n0.21691678\n0.049751244\n0.6457143\n0.35428571\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n    5\n1\n53\n0.3291925\n212\n0.07230559\n0.21691678\n0.28922237\n0.074626866\n1.0000000\n0.00000000\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n    6\n1\n47\n0.2955975\n259\n0.06412005\n0.28922237\n0.35334243\n0.104477612\n0.1680851\n0.83191489\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n    7\n1\n44\n0.2784810\n303\n0.06002729\n0.35334243\n0.41336971\n0.139303483\n0.7772727\n0.22272727\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n    8\n1\n71\n0.2253968\n374\n0.09686221\n0.41336971\n0.51023192\n0.179104478\n0.8943662\n0.10563380\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n    10\n1\n34\n0.1954023\n408\n0.04638472\n0.51023192\n0.55661664\n0.228855721\n1.0000000\n0.00000000\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n    11\n1\n35\n0.2348993\n443\n0.04774898\n0.55661664\n0.60436562\n0.283582090\n0.9085714\n0.09142857\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n    12\n1\n50\n0.2450980\n493\n0.06821282\n0.60436562\n0.67257844\n0.343283582\n1.0000000\n0.00000000\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n    13\n1\n28\n0.2105263\n521\n0.03819918\n0.67257844\n0.71077763\n0.407960199\n0.7178571\n0.28214286\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n    14\n1\n56\n0.2121212\n577\n0.07639836\n0.71077763\n0.78717599\n0.477611940\n1.0000000\n0.00000000\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n    15\n1\n19\n0.1666667\n596\n0.02592087\n0.78717599\n0.81309686\n0.552238806\n0.4947368\n0.50526316\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n    16\n1\n26\n0.1870504\n622\n0.03547067\n0.81309686\n0.84856753\n0.631840796\n1.0000000\n0.00000000\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n    17\n1\n35\n0.1699029\n657\n0.04774898\n0.84856753\n0.89631651\n0.716417910\n1.0000000\n0.00000000\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n    18\n1\n23\n0.2169811\n680\n0.03137790\n0.89631651\n0.92769441\n0.805970149\n0.1173913\n0.88260870\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n    19\n1\n32\n0.1828571\n712\n0.04365621\n0.92769441\n0.97135061\n0.900497512\n1.0000000\n0.00000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n    20\n1\n21\n0.1265060\n733\n0.02864939\n0.97135061\n1.00000000\n1.000000000\n1.0000000\n0.00000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n  \n  \n  \n\n\n\n\nTu put the code above into a function:\n\ndecile_dummies <- function(data, rangeleft, rangeright){\n\ndata %>% \n  mutate(d1 = ifelse({{rangeleft}} >= 0 & {{rangeleft}} < 0.1, 1, 0),\n         d2 = ifelse({{rangeleft}} %[]% c(0.1, 0.2) | {{rangeright}} %[]% c(0.1, 0.2), 1, 0),  #%[]% is an within bracket operator from the Desctools package. for example, x %[]% c(a, b) checks whether x belong to the interval [a, b] with a<b \n         d3 = ifelse({{rangeleft}} %[]% c(0.2, 0.3) | {{rangeright}} %[]% c(0.2, 0.3), 1, 0),\n         d4 = ifelse({{rangeleft}} %[]% c(0.3, 0.4) | {{rangeright}} %[]% c(0.3, 0.4), 1, 0),\n         d5 = ifelse({{rangeleft}} %[]% c(0.4, 0.5) | {{rangeright}} %[]% c(0.4, 0.5), 1, 0),\n         d6 = ifelse({{rangeleft}} %[]% c(0.5, 0.6) | {{rangeright}} %[]% c(0.5, 0.6), 1, 0),\n         d7 = ifelse({{rangeleft}} %[]% c(0.6, 0.7) | {{rangeright}} %[]% c(0.6, 0.7), 1, 0),\n         d8 = ifelse({{rangeleft}} %[]% c(0.7, 0.8) | {{rangeright}} %[]% c(0.7, 0.8), 1, 0),\n         d9 = ifelse({{rangeleft}} %[]% c(0.8, 0.9) | {{rangeright}} %[]% c(0.8, 0.9), 1, 0),\n         d10 = ifelse({{rangeleft}} %[]% c(0.9, 1) | {{rangeright}} %[]% c(0.9, 1), 1, 0))\n  \n}\n\nThis compute the proportion of the first decile directly from the table above:\n\nweighted.mean(x = table.income$prop_vote[table.income$d1 == 1], w = table.income$share_decile[table.income$d1 == 1]) # d1\n\n[1] 0.301588\n\n\nLet’s try to compute the 3 first decile in a way that can then be put into a for loop or even into a function later\n\n# for d_i\n\nweighted.mean(x = c(table.income$prop_vote[table.income[,12] == 1]),\n              w = c(table.income$share_decile[table.income[,12] == 1])) #d1: take columns 11 (D1) and the values of prop vote and share decile for which D11 == 1\n\n[1] 0.301588\n\nweighted.mean(x = c(table.income$prop_vote[table.income[,13] == 1]),\n              w = c(table.income$share_rest[table.income[,12] == 1 & table.income[, 13] == 1],\n                    table.income$share_decile[table.income[,12] == 0 & table.income[,13] == 1])) #d2\n\n[1] 0.2350616\n\nweighted.mean(x = c(table.income$prop_vote[table.income[,14] == 1]),\n              w = c(table.income$share_rest[table.income[,14-1] == 1 & table.income[, 14] == 1], #d3\n                    table.income$share_decile[table.income[14-1] == 0 & table.income[,14] == 1]))\n\n[1] 0.2985395\n\n\nLet’s try the for loop\n\ndecile_vec <- rep(NA, 10)\ndecile <- c()\n#11:20 are the decile dummies columns in the dataset\ndecile_vec <- capture.output(for (i in 12:21) {\n\n  if(i == 12){\n    \n  decile =  c(weighted.mean(x = c(table.income$prop_vote[table.income[,i] == 1]),\n              w = c(table.income$share_decile[table.income[,i] == 1])))\n  }else{\n    \n   decile = c(weighted.mean(x = c(table.income$prop_vote[table.income[,i] == 1]),\n              w = c(table.income$share_rest[table.income[,i-1] == 1 & table.income[, i] == 1], \n                    table.income$share_decile[table.income[i-1] == 0 & table.income[,i] == 1])))\n  }\n \ncat(decile,\"\\n\")\n})\n\ndecile_vec <- as.numeric(decile_vec)\ndecile <- data.frame(decile = 1:10,\n                         prop = decile_vec)\ndecile\n\n   decile      prop\n1       1 0.3015880\n2       2 0.2350616\n3       3 0.2985395\n4       4 0.2873299\n5       5 0.2359808\n6       6 0.2147917\n7       7 0.2308659\n8       8 0.1992121\n9       9 0.1779249\n10     10 0.1737567\n\n\nThis seems to work, the 3 first values are the same as the ones computed above\n\ndecile %>% \n  ggplot()+\n  aes(x = factor(decile), y = prop)+\n  geom_col()+\n  theme_bw()\n\n\n\n\nThis graph is very close to the one from the techninal note (figure one, right-sided graph)\n\n\n\n\n\nFor now, let’s put the for loop into a function: this function would require the decile dummies columns, the columns for the proportion, the column for decile share and the column for the rest’s share:\n\ndecile <- function(data, columns, prop, share_decile, share_rest){\n  \n  decile_vec <- rep(NA, 10)\ndecile <- c()\n\ndecile_vec <- capture.output(for (i in min(columns):max(columns)) {\n\n  if(i == min(columns)){\n    \n  decile =  c(weighted.mean(x = c(prop[data[,i] == 1]),\n              w = c(share_decile[data[,i] == 1])))\n  }else{\n    \n   decile = c(weighted.mean(x = c(prop[data[,i] == 1]),\n              w = c(share_rest[data[,i-1] == 1 & data[, i] == 1], \n                    share_decile[data[i-1] == 0 & data[,i] == 1])))\n  }\n \ncat(decile,\"\\n\")\n})\n\ndecile_vec <- as.numeric(decile_vec)\ndecile <- data.frame(decile = 1:10,\n                         prop = decile_vec)\ndecile\n}\n\n\ndecile(data = table.income, columns = 12:21, prop = table.income$prop_vote, share_decile = table.income$share_decile, share_rest = table.income$share_rest)\n\n   decile      prop\n1       1 0.3015880\n2       2 0.2350616\n3       3 0.2985395\n4       4 0.2873299\n5       5 0.2359808\n6       6 0.2147917\n7       7 0.2308659\n8       8 0.1992121\n9       9 0.1779249\n10     10 0.1737567\n\n\nThe function seems to work, but requires a specific dataframe (formatted as table.income)."
  },
  {
    "objectID": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#reproducing-wpid-results-france-in-progress",
    "href": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#reproducing-wpid-results-france-in-progress",
    "title": "From income brackets to income decile",
    "section": "Reproducing WPID results: France (in progress)",
    "text": "Reproducing WPID results: France (in progress)"
  },
  {
    "objectID": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#sidenote-fitting-a-pareto-line-to-income-brackets",
    "href": "posts/Techinal notes of political cleavages and inequality/technical note piketty 2021.html#sidenote-fitting-a-pareto-line-to-income-brackets",
    "title": "From income brackets to income decile",
    "section": "Sidenote: fitting a Pareto line to income brackets",
    "text": "Sidenote: fitting a Pareto line to income brackets\nFinally, one can also try to fit a “Pareto line” to the income bracket data. Vilfredo Pareto (1848-1923) is well-known for being one of the first economist to have computed inequality indices (his famous alpha coefficient) directly from personal income distribution data. His relationship \\(log(N) = A-\\alpha log(x)\\), with N the number of people earning more than income level x, is a famous relationship and almost every course on income inequality measurement starts with it.\nFirst, a table need to be constructed from the data, we count the number of observation per income bracket and compute the inverse of the cumulative relative frequencies, which is the same as N is Pareto’s equation.\n\nca2015 %>% \n  count(inc) %>% \n  mutate(prop = n/sum(n),\n         cumrelfreq = cumsum(prop),\n         inverse_rcdf = rev(cumrelfreq)) -> paretotable\n\nparetotable %>% \n  gt()\n\n\n\n\n\n  \n  \n    \n      inc\n      n\n      prop\n      cumrelfreq\n      inverse_rcdf\n    \n  \n  \n    1\n211\n0.04687847\n0.04687847\n1.00000000\n    2\n327\n0.07265052\n0.11952899\n0.87136192\n    3\n79\n0.01755166\n0.13708065\n0.82914908\n    4\n210\n0.04665630\n0.18373695\n0.78626972\n    5\n199\n0.04421240\n0.22794934\n0.75960898\n    6\n184\n0.04087980\n0.26882915\n0.70451011\n    7\n188\n0.04176850\n0.31059764\n0.66985114\n    8\n421\n0.09353477\n0.40413242\n0.64185737\n    10\n205\n0.04554543\n0.44967785\n0.57209509\n    11\n166\n0.03688069\n0.48655854\n0.53921351\n    12\n237\n0.05265497\n0.53921351\n0.48655854\n    13\n148\n0.03288158\n0.57209509\n0.44967785\n    14\n314\n0.06976228\n0.64185737\n0.40413242\n    15\n126\n0.02799378\n0.66985114\n0.31059764\n    16\n156\n0.03465896\n0.70451011\n0.26882915\n    17\n248\n0.05509887\n0.75960898\n0.22794934\n    18\n120\n0.02666074\n0.78626972\n0.18373695\n    19\n193\n0.04287936\n0.82914908\n0.13708065\n    20\n190\n0.04221284\n0.87136192\n0.11952899\n    NA\n579\n0.12863808\n1.00000000\n0.04687847\n  \n  \n  \n\n\n\n\nFinally, one can plot the log of the inverse of the relative cumulative distribution function against the log of the income groups:\n\nparetotable %>% \n  ggplot()+\n  aes(x = log(inc), y = log(rev(cumrelfreq)))+\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  theme_bw()\n\n\n\n\nWe can see that the line does not fit the data very well. As explained by Milanovic, the Pareto line fits well only for the top of income distribution. In fact, the data on personal income distribution that Pareto had only collected income data of the very rich. If he had data covering more than the top 1 percent, he would have probably made similar graphs as here and as in Milanovic’s blog post."
  },
  {
    "objectID": "Reproducing WPID's results/wpid results.html",
    "href": "Reproducing WPID's results/wpid results.html",
    "title": "Reproducing WPID’s results",
    "section": "",
    "text": "To analyze the evolution of political cleavages, Piketty et al (2021) compiled datasets covering a lot of countries.\n\n\n\n\nchinc <- read_dta(\"ch-inc.dta\")\nnames(chinc)\n\n  [1] \"iso\"          \"isoname\"      \"year\"         \"survey\"       \"source\"      \n  [6] \"type\"         \"id\"           \"weightorig\"   \"vote\"         \"voteprev\"    \n [11] \"lrs\"          \"turnout\"      \"intpol\"       \"age\"          \"educ\"        \n [16] \"educ2\"        \"emp\"          \"house\"        \"inc\"          \"marital\"     \n [21] \"region\"       \"religion\"     \"religious\"    \"rural\"        \"rural2\"      \n [26] \"sector\"       \"sex\"          \"union\"        \"educ3\"        \"region2\"     \n [31] \"language\"     \"ctrbirth\"     \"occup_kriesi\" \"occup_oesch\"  \"self\"        \n [36] \"partyid\"      \"Group\"        \"voteleft\"     \"voteright\"    \"voteother\"   \n [41] \"weight\"       \"votesoci\"     \"votechri\"     \"votelibe\"     \"voteecol\"    \n [46] \"voteextr\"     \"voteothe\"     \"univ\"         \"year2\"        \"educ_1\"      \n [51] \"educ_2\"       \"educ_3\"       \"emp_1\"        \"emp_2\"        \"emp_3\"       \n [56] \"religious_1\"  \"religious_2\"  \"religious_3\"  \"religion_1\"   \"religion_2\"  \n [61] \"religion_3\"   \"religion_4\"   \"sex_1\"        \"sex_2\"        \"region_1\"    \n [66] \"region_2\"     \"region_3\"     \"language_1\"   \"language_2\"   \"language_3\"  \n [71] \"ctrbirth_1\"   \"ctrbirth_2\"   \"agerec\"       \"agerec_1\"     \"agerec_2\"    \n [76] \"agerec_3\"     \"surveyid\"     \"identifier\"   \"id2\"          \"dinc_1\"      \n [81] \"dinc_2\"       \"dinc_3\"       \"dinc_4\"       \"dinc_5\"       \"dinc_6\"      \n [86] \"dinc_7\"       \"dinc_8\"       \"dinc_9\"       \"dinc_10\"      \"dinc\"        \n [91] \"qinc\"         \"qinc_1\"       \"qinc_2\"       \"qinc_3\"       \"qinc_4\"      \n [96] \"qinc_5\"       \"ginc\"         \"ginc_1\"       \"ginc_2\"       \"ginc_3\"      \n[101] \"b50\"         \n\n\n\nlm1 <- lm(data = chinc, voteleft ~ ginc_3 + factor(year) + educ)\nsummary(lm1)\n\n\nCall:\nlm(formula = voteleft ~ ginc_3 + factor(year) + educ, data = chinc)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6117 -0.4013 -0.3214  0.5859  0.8800 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       0.218977   0.016673  13.134  < 2e-16 ***\nginc_3           -0.070445   0.008380  -8.407  < 2e-16 ***\nfactor(year)1979 -0.115305   0.021381  -5.393 6.97e-08 ***\nfactor(year)1995 -0.066702   0.016000  -4.169 3.07e-05 ***\nfactor(year)1999 -0.103853   0.017267  -6.015 1.82e-09 ***\nfactor(year)2003 -0.079407   0.016168  -4.911 9.09e-07 ***\nfactor(year)2007 -0.135868   0.016622  -8.174 3.07e-16 ***\nfactor(year)2011 -0.100260   0.016532  -6.065 1.33e-09 ***\nfactor(year)2015 -0.159405   0.016477  -9.675  < 2e-16 ***\nfactor(year)2019 -0.015055   0.016127  -0.934    0.351    \neduc              0.130890   0.004706  27.816  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4824 on 41221 degrees of freedom\n  (35899 observations effacées parce que manquantes)\nMultiple R-squared:  0.02731,   Adjusted R-squared:  0.02708 \nF-statistic: 115.7 on 10 and 41221 DF,  p-value: < 2.2e-16\n\n\n\nlm1975 <- lm(data = chinc[chinc$year == 1975,], voteleft ~ ginc_3, weights = weightorig)\nsummary(lm1975)\n\n\nCall:\nlm(formula = voteleft ~ ginc_3, data = chinc[chinc$year == 1975, \n    ], weights = weightorig)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-0.4184 -0.3951 -0.3951  0.5493  0.5493 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.41838    0.01592  26.281   <2e-16 ***\nginc_3       0.01605    0.04748   0.338    0.735    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4666 on 1083 degrees of freedom\n  (1272 observations effacées parce que manquantes)\nMultiple R-squared:  0.0001055, Adjusted R-squared:  -0.0008178 \nF-statistic: 0.1142 on 1 and 1083 DF,  p-value: 0.7354"
  },
  {
    "objectID": "posts/Vote for the left in Switzerland a simple analysis/select2019analysis.html#complexifying-the-model",
    "href": "posts/Vote for the left in Switzerland a simple analysis/select2019analysis.html#complexifying-the-model",
    "title": "The vote for the left in the 2015 Swiss National Council Election: a short analysis",
    "section": "Complexifying the model",
    "text": "Complexifying the model\n\nHierarchical model\nOne possible and interesting way to complexify the model is to include the different Swiss canton into the regression. In fact, the previous regression model can be considered as a “complete pooling” model in which I made the asumption that the slopes of the coefficients do not vary by cantons. However, cantons represents an important level of analysis in Switzerland, because elections and politics are a lot structures at the cantonal level. Cantons can thus be considered as levels in which the observed individuals in our sample are grouped.\nAccording to Gelman and Hill (2007) there are two main differents ways to consider these groups in regression analysis:\n\nNo pooling models: the slopes and/or the intercepts are allowed to vary across the groups freely.\nPartial pooling models: the slopes and/or the intercepts are allowed to vary, but they are modeled (we consider that they follow a normal distribution)\n\nIn the present analysis, I will consider a partial pooling model in which the slopes and intercepts for income and education can vary. In R, partial pooling models can be estimated with the function lmer() from the lme4 package.\nThe results of this model can be then represented through a table with tab_model()\n\ntab_model(glmer1, transform = NULL, title = \"Partial Pooling model\", digits = 3)\n\n\n\nPartial Pooling model\n\n \nvote.left\n\n\nPredictors\nLog-Odds\nCI\np\n\n\n(Intercept)\n-1.142\n-1.469 – -0.815\n<0.001\n\n\nGross monthly householdincome, W1 updated withW4\n-0.078\n-0.098 – -0.058\n<0.001\n\n\nEducation.level\n0.116\n0.095 – 0.138\n<0.001\n\n\nRandom Effects\n\n\n\nσ2\n3.29\n\n\n\nτ00 W1_3_canton_sample\n0.40\n\n\nτ11 W1_3_canton_sample.Education.level\n0.00\n\n\nτ11 W1_3_canton_sample.Gross.monthly.hh.income\n0.00\n\n\nρ01\n-0.93\n\n\n\n-0.68\n\n\nICC\n0.06\n\n\nN W1_3_canton_sample\n26\n\nObservations\n5607\n\n\nMarginal R2 / Conditional R2\n0.043 / 0.102\n\n\n\n\n\n\nThe random effects coefficients at the cantons level for income and education are 0, which implies that there is very low variation between cantons. Furthermore, the fixed effect coefficients are almost the same than the previous model: this new model is thus not a big improvement and shows that including cantons as a group does not change the model a lot.\nHowever, it is still interesting to plot predicted probabilities to have a better overview:\n\nplot_predictions(glmer1, condition = c(\"Education.level\", \"Gross.monthly.hh.income\", \"W1_3_canton_sample\"))+facet_wrap(~W1_3_canton_sample)+\n  aes(linetype = Gross.monthly.hh.income)+\n  scale_colour_brewer(palette = \"Set1\")+\n  labs(title = \"Probabilités prédites selon le niveau d'éducation, pour chaque canton et pour différent niveau de revenu\",\n       subtitle = \"Election Conseil National 2015\")+\n  geom_hline(yintercept = 0.5, alpha = 0.8)\n\n\n\n\n\n\n\n\nThe relationship between the predicted probabilities to vote for the left and education is positive for every cantons. There are a lot of cantons that show similar relationships and curves and whose predicted probabilities, despite the positive link with education, do not go above 0.5 (with some exception such as Aargau, Thurgau, Tessin, Valais, Glarus…). The cantons which show different patterns are Basel-Stadt, Geneva, Jura, Vaud and Neuchâtel with higher predicted probabilities.\n\n\nAdding control variables\nLet’s now add some control variables to the model. The models above are flawed by the fact that there are only two regressors. One important assumption of regression models are the mean independence of the covariates with the error term. The model is assumed to include all the important explanatory variables in the model. If not, the estimates will be biased, so one can suspect that the coefficients estimates for this first model are heavily biased.\nI expand the first model by including a dummy for gender (1= female, 0 = male), age and nonreligiosity (takes value 1 to 7, 1 is for going to the church a lot, 7 is for never at all)\nreg2 <- glm(data = datareg, vote.left ~ Gross.monthly.hh.income + Education.level + W1_agecat + nonreligious + gender, family=binomial(link=\"logit\"))\nstargazer(reg, reg2, type = \"html\", title = \"Model 2: include control variables | log(odds)\")\n\n\n\nModel 2: include control variables | log(odds)\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nvote.left\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nGross.monthly.hh.income\n\n\n-0.077***\n\n\n-0.060***\n\n\n\n\n\n\n(0.008)\n\n\n(0.010)\n\n\n\n\n\n\n\n\n\n\n\n\nEducation.level\n\n\n0.118***\n\n\n0.117***\n\n\n\n\n\n\n(0.009)\n\n\n(0.012)\n\n\n\n\n\n\n\n\n\n\n\n\nW1_agecat\n\n\n\n\n0.042*\n\n\n\n\n\n\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\nnonreligious\n\n\n\n\n0.159***\n\n\n\n\n\n\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\ngenderFemale\n\n\n\n\n0.594***\n\n\n\n\n\n\n\n\n(0.075)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-1.049***\n\n\n-2.642***\n\n\n\n\n\n\n(0.083)\n\n\n(0.218)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n5,607\n\n\n3,715\n\n\n\n\nLog Likelihood\n\n\n-3,559.022\n\n\n-2,190.866\n\n\n\n\nAkaike Inf. Crit.\n\n\n7,124.044\n\n\n4,393.731\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\nThe estimated income coefficient is even closer to zero after controls, suggesting an even lower link between income group and the probability to vote for the left. However, the coefficient for education level has increased. Age category is linked positively with the vote for the left. The coefficient for gender implies that, ceteris paribus, women vote on probabiliy 0.43 more than men for the left. It would be interesting to see how the model changes if an interaction term between education and income is included. This interaction would allow the the slope for education and income to vary according to each other’s values:\nreg3 <- glm(data = datareg, vote.left ~ Gross.monthly.hh.income + Education.level + W1_agecat + nonreligious + gender + Gross.monthly.hh.income:Education.level, family=binomial(link=\"logit\"))\n\nstargazer(reg, reg2, reg3, type = \"html\", title = \"Model 3: include control variables & interaction | log(odds)\")\n\n\n\nModel 3: include control variables & interaction | log(odds)\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nvote.left\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n\n\n\n\n\n\nGross.monthly.hh.income\n\n\n-0.077***\n\n\n-0.060***\n\n\n-0.091***\n\n\n\n\n\n\n(0.008)\n\n\n(0.010)\n\n\n(0.029)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEducation.level\n\n\n0.118***\n\n\n0.117***\n\n\n0.095***\n\n\n\n\n\n\n(0.009)\n\n\n(0.012)\n\n\n(0.023)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW1_agecat\n\n\n\n\n0.042*\n\n\n0.041*\n\n\n\n\n\n\n\n\n(0.022)\n\n\n(0.022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnonreligious\n\n\n\n\n0.159***\n\n\n0.159***\n\n\n\n\n\n\n\n\n(0.026)\n\n\n(0.026)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngenderFemale\n\n\n\n\n0.594***\n\n\n0.594***\n\n\n\n\n\n\n\n\n(0.075)\n\n\n(0.075)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGross.monthly.hh.income:Education.level\n\n\n\n\n\n\n0.003\n\n\n\n\n\n\n\n\n\n\n(0.003)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-1.049***\n\n\n-2.642***\n\n\n-2.455***\n\n\n\n\n\n\n(0.083)\n\n\n(0.218)\n\n\n(0.273)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n5,607\n\n\n3,715\n\n\n3,715\n\n\n\n\nLog Likelihood\n\n\n-3,559.022\n\n\n-2,190.866\n\n\n-2,190.235\n\n\n\n\nAkaike Inf. Crit.\n\n\n7,124.044\n\n\n4,393.731\n\n\n4,394.470\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n\n\nVizualizations\n\nreg3 %>% plot_predictions(condition = c(\"Gross.monthly.hh.income\", \"Education.level\", \"gender\")) + facet_wrap(~Education.level + gender)\n\n\n\n\n\n\n\nreg3 %>% plot_predictions(condition = c(\"Education.level\", \"Gross.monthly.hh.income\", \"gender\")) + facet_wrap(~Gross.monthly.hh.income + gender)"
  },
  {
    "objectID": "posts/trust institution switzerland/trust institution switzerland.html",
    "href": "posts/trust institution switzerland/trust institution switzerland.html",
    "title": "How did the trust in institutions evolve in Switzerland in the last decades? An analysis of political stability and trust",
    "section": "",
    "text": "Switzerland is often considered as a successful and well-performing economy. The country typically ranks among the firsts in a wide variety of living standard measures such as the human development index, GDP per capita and so on. Along with the good performances of the economy, one expects that Swiss people also have more trust in their institutions compared with other countries. If one looks at, for instance, the data provided by the OECD on the confidence in government and other institutions, Switzerland is indeed one of the countries with the highest level of trust:\n\n\n\nSource: OECD (Government at Glance, 2021)\n\n\nIn Switzerland, the confidence in national government in 2020 was the highest among OECD countries with a level of 85%. Other countries like France and Italy have a level of confidence lower than the average.\n\n\n\nSource: OECD (Government at Glance, 2021)\n\n\nIf one looks at other data provided by the OECD, Switzerland still ranks among the highest. In the graph above, Swiss people show a great deal of confidence in the police (about 85%), parliament (60%) and government (70%). This stands in sharp contrast with France, Italy and the US (which shows very low level of confidence in parliament with 15%). If one tries therefore to assess the evolution of trust in institutions in Switzerland, one thus expects to find a great stability. Nonetheless, one period in recent Swiss history represents an exception: the crisis of the 1990s. This period was marked by recession and was accompanied by a decline in trust in institutions (Brunner and Sgier 1997).\nBut why is the evolution of trust in institutions importance? For my research, I am interested in social conflict, political cleavages and institutional change. The Neorealism approach developped by Amable and Palombarini (2005; 2008), which is dedicated to the analysis of those topics, offers insightful concepts and methods that I will mobilize here in assessing the evolution of Switzerland’s trust in its institutions in the last decades. Until now, Neorealism has been first and foremost mobilized by its founders to analyse France and Italy (Bruno Amable and Palombarini 2014, 2018). In their work, they typically start with the fact that Italy and France went under periods of deep political crises. Leaving their conceptual definitions of crisis (which are really interesting) aside and focusing only on how they identify it empirically, they typically expose data on trust in politicians, institutions, government and in political turnover. However, it is rather straightforward to anyone interested in politics and contemporary history that Italy and France underwent political crises, and data like the ones above only serve to describe a well-known fact. The situation is totally different for Switzerland, which is why it is interesting to study this country in a Neorealist approach.\nThis post will hence be an attempt to periodize, analyse and assess the evolution of trust in institutions in Switzerland. The goal here is, by using post-electoral survey, to identify the trends in trust in institutions and assess whether Switzerland can be characterized as a politically stable country, as opposed to France and Italy. The figures above already show that Switzerland is characterized with a relatively high level of trust, so the objective here is to explore other data which also allow to see the temporal evolution.\n\n\nTo do so, I will analyse post-electoral survey data. The Swiss Election Studies (SELECTS) offers a cumulative dataset which is of particular interest.\n\n\n\nThis dataset is in fact a harmonized dataset of all the successive post-electoral studies that have been conducted in Switzerland between 1971 and 2019 by different universities. This dataset contains a set of “trust in political institutions” variables which are of interest, but not all of them can be used because they are not avaliable for each year of the dataset. The ones which have the most time coverage are the following variables and that I will analyse here are described in the following table\n\n\n\n\n\n\n\n\n\nCode\nname\nvalues\nYears\n\n\n\n\ntrust1\ntrust in federal council\n0 (no trust) to 10 (full trust) with decimal values\nnot 1979, 2015, 2019\n\n\ntrust2\ntrust in national parliament\n0 (no trust) to 10 (full trust) with decimal values\n1991, 1995, 1999, 2003, 2007, 2011\n\n\ntrust3\ntrust in cantonal authorities\n0 (no trust) to 10 (full trust) with decimal values\n1995, 1999, 2003, 2007, 2011\n\n\ntrust5\ntrust in national political parties\n0 (no trust) to 10 (full trust) with decimal values\n1999, 2003, 2007, 2011\n\n\neps1\nevaluation: political system/democracy\nscale from 0 to 1, with decimal values\n1971, 1979, 1995, 1999, 2003, 2007, 2011, 2015, 2019"
  },
  {
    "objectID": "posts/trust institution switzerland/trust institution switzerland.html#trust-in-federal-council",
    "href": "posts/trust institution switzerland/trust institution switzerland.html#trust-in-federal-council",
    "title": "How did the trust in institutions evolve in Switzerland in the last decades? An analysis of political stability and trust",
    "section": "Trust in Federal Council",
    "text": "Trust in Federal Council\n\n\n\n\n\nHere is a basic visualisation to show the distribution of the variable for each year. It is strinking how the distribution is almost the same for the years 1971-1975-1987 and then from 1995 to 2011. This suggests a great stability of trust in Federal Council, which seems positive. However, since the graph above is rather difficult to interpret due to the fact that it carries too much information and the scales change through the years, I will create an indicator variable to simplify the information. The dummy variable will take value 1 if the respondent takes a value higher than 5 (the middle point level of indifference), and 0 otherwise.\n\n\n\n\n\n\n\n\nThe graph above represents the percentage of respondents who declared to always or most of the time trust the federal council. The only period this trust declined was between 1975 and 1991. However, one should be cautious with the strong decline in 1991, because the scale (number of values the ordinal variable can take) changes for the first time for this year (see the precedent graph above). In fact, the strong decline in 1991 is surely due to the fact that the scale, by including more response choices in the survey (from 4 to 7 points scale), perhaps induced more middle-point responses (the middle answer is the mode for 1991). From 1995 to 2011, the trust in federal council shows a great stability, and even increases between 2007 and 2011. Nonetheless, the variable does include years after 2011, which is unfortunate. Fortunately, there are other variables which cover a bigger time frame. In this regard, the variable on the evaluation of the Swiss democracy/political system (eps1) is interesting:\n\n\n\n\n\n\n\n\nThe graph above shows how strong trust in institutions is in Switzerland and that the latter has even increased in the last years until 2019. Note that the data for 1995 have the same problem as for the year 1991 in the previous graph (change in the variable’s number of categories). I can thus conclude that the trust in institutions is not only stable in Switzerland, but even increasing. One further step, however, is to look at how trust changes if one takes education and income levels into account: do poorer people and less educated people have less trust in institutions in Switzerland? We will see that the picture is slightly more contrasted trust is analyzed for each income level.\n\n\n\n\n\nTaking into account income quintiles offer a slightly more contrasted results, but trust is high even for low income levels. There is no strong differences in trust if we compare the lowest quintile with the highest (with still somme difference in each year), but one can see that trust increases with income group: richer Swiss people (in terms of income) have more confidence in the political system/democracy in this sample.\nSince the dataset also gives the education group, one can do the same graph above with education:\n\n\n\n\n\nThere is overall a positive association between education level and trust in democracy/political system, even though trust is high and systematically above 50% in each year (with one exception for 1979).\n\nAlternative data source: the European Social Survey (ESS)\nIt is often necessary to run similar analysis on different data sources to check whether the results obtained are robust. To do so, I will now analyse the swiss trust in institutions using ESS data. Since the ESS does not provide a cumulative dataset, I will simply analyse the first available (2002) and the most recent one (2020).\n\n\n\n\n\n\n\n\nvariable\nname\nscale\n\n\n\n\ntrstplt\ntrust in politician\n0 = no trust, 10 = complete trust (discrete scale)\n\n\ntrstprl\nTrust in country’s parliament\n0 = no trust, 10 = complete trust (discrete scale)\n\n\nstfeco\nHow satisfied with present state of economy in country\n0 = extremely dissatisfied, 1 = extremely satisfied (discrete scale)\n\n\nstfgov\nHow satisfied with the national government\n0 = extremely dissatisfied, 1 = extremely satisfied (discrete scale)\n\n\nstfdem\nHow satisfied with the way democracy works in country\n0 = extremely dissatisfied, 1 = extremely satisfied (discrete scale)\n\n\nagea\nAge of respondent, calculated\n\n\n\nedulvla\nHighest level of education\n0 = not possible to harmonize, 1 = less than secondary, 5 = tertiary education completed\n\n\nedlvch\nHighest level of education (Switzerland)\n1 = incomplete compulsory school, 15 = university, 16 = other (discrete scale)\n\n\nhinctnt\nHousehold’s total net income, all sources\n\n\n\n\nAn advantage of the ESS data compared with Selects is the comparability of the trust in institutions variables. As we saw in the first graphs, Selects have changed the scale of their variables through the years, which makes comparison difficult even with a cumulative and harmonized dataset. ESS variables (see table above) do not change their scale, so one can compare data from 2002 and 2020 without facing the problems I had with Selects data.\n\n\nWarning: le package 'naniar' a été compilé avec la version R 4.2.3\n\n\nLet’s first have a look at how the variable is distributed for a given year, for instance 2020:\n\n\n\n\n\nThe graph is coherent with all the previous data we saw: most Swiss people have confidence and trust in the politicians of their country in 2020. What about the evolution of this trust if one looks at all the rounds provided by ESS since 2002? To have a look a this, I load all the ESS rounds, create an indicator variable (still fromthe same variable, trstplt) taking value 1 if the respondent takes at least value 5 and plot the proportion for each year:\n\n\n\n\n\nIf one considers trust in politicians as a good indicator of political stability, Switzerland shows a great and increasing level of stability and it would be difficult to say that the country has known any deep political crisis in the last years. The political stability of Switzerland is even more striking when compared with countries which have known instability and systemic crises such as Italy and France:"
  }
]